{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2617147a-5efd-4572-9ac0-6b48d1269fa3",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "To work with any kind of data we first have to load it. For this we use a dataloader that reads the images as well as their labels and transforms them into pytorch readable tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d80171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0090711b-668a-4bab-a4d7-686081d239cb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class RSiMCCDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        # get images\n",
    "        image_files = [x.resolve() for x in pathlib.Path(\".\").glob('data/*/*')]\n",
    "        # Image.open() has a bug, this is a workaround\n",
    "        self.images=[read_image(str(p)) for p in image_files] \n",
    "        # get labels from image path\n",
    "        labels = [x.parts[-2] for x in image_files]\n",
    "        self.classes = sorted(list(set(labels)))\n",
    "        self.labels = [self.label_to_tensor(lbl) for lbl in labels]\n",
    "\n",
    "        assert len(self.labels) == len(self.images), f\"Found {len(self.labels)} labels and {len(self.images)} images\"\n",
    "\n",
    "    def label_to_tensor(self, lbl):\n",
    "        \"\"\"\n",
    "        Converts the string label to a one-hot tensor where every entry is zero except the label which is one.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert lbl in self.classes, f\"Class {lbl} not a valid class (valid classes: {self.classes})\"\n",
    "        t = torch.zeros(len(self.classes))\n",
    "        t[self.classes.index(lbl)] = 1\n",
    "        return t\n",
    "\n",
    "    def tensor_to_label(self, t):\n",
    "        \"\"\"\n",
    "        Returns the classname in string format\n",
    "        \"\"\"\n",
    "        assert len(t.shape) == 1, f\"Can only convert 1-dimensional tensors (shape of tensor: {t.shape})\"\n",
    "        assert len(t) == len(self.classes), f\"Lenght of tensor ({len(t)}) does not match number of classes ({len(self.classes)})\"\n",
    "        return self.classes[t.argmax()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].float()/255\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685aa618-6d38-4ff5-bac6-2e16f8c7a25e",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Now lets load the dataset and look at some examples by just randomly loading the images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673f108f-b1c0-4ab8-a331-3a6d038d2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RSiMCCDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8257cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 11519 RGB images of shape torch.Size([3, 64, 64]) labeled in 10 classes which are AnnualCrop, Forest, HerbaceousVegetation, Highway, Industrial, Pasture, PermanentCrop, Residential, River, SeaLake\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset consists of {len(dataset)} RGB images of shape {dataset.images[0].shape} labeled in {dataset.labels[0].shape[0]} classes which are \" + ', '.join(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88aefed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 48,  47,  48,  ..., 146, 145, 151],\n",
       "         [ 48,  48,  48,  ..., 146, 147, 150],\n",
       "         [ 47,  48,  46,  ..., 150, 150, 151],\n",
       "         ...,\n",
       "         [ 51,  50,  52,  ...,  69,  83,  76],\n",
       "         [ 52,  51,  49,  ...,  91,  94,  92],\n",
       "         [ 50,  51,  54,  ..., 112,  99,  78]],\n",
       "\n",
       "        [[ 75,  74,  75,  ..., 130, 128, 128],\n",
       "         [ 75,  75,  74,  ..., 130, 128, 129],\n",
       "         [ 76,  74,  72,  ..., 131, 129, 128],\n",
       "         ...,\n",
       "         [ 76,  77,  79,  ...,  84,  95,  87],\n",
       "         [ 77,  78,  75,  ..., 104, 105, 100],\n",
       "         [ 75,  75,  78,  ..., 124, 110,  89]],\n",
       "\n",
       "        [[ 96,  95,  96,  ..., 133, 134, 136],\n",
       "         [ 96,  96,  97,  ..., 133, 134, 136],\n",
       "         [ 94,  97,  97,  ..., 135, 134, 136],\n",
       "         ...,\n",
       "         [ 96,  98, 100,  ..., 105, 117, 109],\n",
       "         [ 97,  99,  98,  ..., 121, 125, 123],\n",
       "         [ 95,  99, 102,  ..., 140, 128, 111]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a81752",
   "metadata": {},
   "source": [
    "# Create my custom convolution model for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609bc17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self, nb_classes):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        # inputs (N,3,64,64)\n",
    "\n",
    "        # Classical processing of images with pattern recognition\n",
    "        # Follows ResNET architecture: Conv2d -> BN -> ReLU (-> MaxPool)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=8)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # no pooling in 1st step\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.bn2   = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5)\n",
    "        self.bn3   = nn.BatchNorm2d(32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # no pooling in 3rd step\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.bn4   = nn.BatchNorm2d(32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=5)\n",
    "        self.bn5   = nn.BatchNorm2d(16)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        # no pooling in 5th step\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.bn6   = nn.BatchNorm2d(16)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.pool6 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "\n",
    "        self.drop7 = nn.Dropout(p=0.05)\n",
    "        self.lin7  = nn.Linear(16*4*4, nb_classes) # adapt here!\n",
    "        \n",
    "    def forward(self, x):        \n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = x + self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = x + self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = x + self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.pool6(x)\n",
    "\n",
    "        # outputs (None, 8, 4, 4)\n",
    "        x = self.drop7(x)\n",
    "        x = self.lin7(x.view(-1, 16*4*4))  # adapt here!\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01bebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(nb_classes):\n",
    "    return DeepCNN(nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dea5346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(len(dataset.classes))\n",
    "dummy_img = torch.rand(42, 3, 64, 64)\n",
    "model(dummy_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ebb7962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: DeepCNN Pages: 1 -->\n",
       "<svg width=\"300pt\" height=\"2743pt\"\n",
       " viewBox=\"0.00 0.00 300.14 2743.07\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2739.07)\">\n",
       "<title>DeepCNN</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-2739.07 296.14,-2739.07 296.14,4 -4,4\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2720.87\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">DeepCNN</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2706.87\" font-family=\"Times,serif\" font-size=\"14.00\">41 tensors total (265.9 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2692.87\" font-family=\"Times,serif\" font-size=\"14.00\">213930 params total (838.8 KB)</text>\n",
       "<!-- input_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input_1</title>\n",
       "<ellipse fill=\"#98fb98\" stroke=\"black\" cx=\"158.5\" cy=\"-35.36\" rx=\"120.83\" ry=\"35.21\"/>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-46.16\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">input_1</text>\n",
       "<text text-anchor=\"start\" x=\"81\" y=\"-32.16\" font-family=\"Times,serif\" font-size=\"14.00\">42x3x64x64 (2.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"126\" y=\"-18.16\" font-family=\"Times,serif\" font-size=\"14.00\">@input.x</text>\n",
       "</g>\n",
       "<!-- conv2d_1_1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>conv2d_1_1</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"253,-170.71 64,-170.71 64,-106.71 253,-106.71 253,-170.71\"/>\n",
       "<text text-anchor=\"start\" x=\"114\" y=\"-156.51\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_1_1</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-142.51\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"74.5\" y=\"-128.51\" font-family=\"Times,serif\" font-size=\"14.00\">params: 64x3x8x8, x64</text>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-114.51\" font-family=\"Times,serif\" font-size=\"14.00\">@conv1</text>\n",
       "</g>\n",
       "<!-- input_1&#45;&gt;conv2d_1_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input_1&#45;&gt;conv2d_1_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-70.95C158.5,-80.18 158.5,-90.21 158.5,-99.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-99.67 158.5,-106.67 160.95,-99.67 156.05,-99.67\"/>\n",
       "</g>\n",
       "<!-- batchnorm_1_2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>batchnorm_1_2</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"253,-270.71 64,-270.71 64,-206.71 253,-206.71 253,-270.71\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-256.51\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_1_2</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-242.51\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-228.51\" font-family=\"Times,serif\" font-size=\"14.00\">params: x64, x64</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-214.51\" font-family=\"Times,serif\" font-size=\"14.00\">@bn1</text>\n",
       "</g>\n",
       "<!-- conv2d_1_1&#45;&gt;batchnorm_1_2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>conv2d_1_1&#45;&gt;batchnorm_1_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-170.72C158.5,-179.83 158.5,-189.91 158.5,-199.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-199.57 158.5,-206.57 160.95,-199.57 156.05,-199.57\"/>\n",
       "</g>\n",
       "<!-- relu_1_3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>relu_1_3</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"253,-356.71 64,-356.71 64,-306.71 253,-306.71 253,-356.71\"/>\n",
       "<text text-anchor=\"start\" x=\"125.5\" y=\"-342.51\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_1_3</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-328.51\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-314.51\" font-family=\"Times,serif\" font-size=\"14.00\">@relu1</text>\n",
       "</g>\n",
       "<!-- batchnorm_1_2&#45;&gt;relu_1_3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>batchnorm_1_2&#45;&gt;relu_1_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-270.77C158.5,-280.04 158.5,-290.19 158.5,-299.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-299.68 158.5,-306.68 160.95,-299.68 156.05,-299.68\"/>\n",
       "</g>\n",
       "<!-- conv2d_2_4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>conv2d_2_4</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"193,-456.71 0,-456.71 0,-392.71 193,-392.71 193,-456.71\"/>\n",
       "<text text-anchor=\"start\" x=\"52\" y=\"-442.51\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_2_4</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-428.51\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-414.51\" font-family=\"Times,serif\" font-size=\"14.00\">params: 64x64x5x5, x64</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-400.51\" font-family=\"Times,serif\" font-size=\"14.00\">@conv2</text>\n",
       "</g>\n",
       "<!-- relu_1_3&#45;&gt;conv2d_2_4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>relu_1_3&#45;&gt;conv2d_2_4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.89,-357.1C135.77,-366.08 128.69,-376.47 121.96,-386.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.75,-385.23 117.84,-392.39 123.8,-387.99 119.75,-385.23\"/>\n",
       "</g>\n",
       "<!-- add_1_5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>add_1_5</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"158.5\" cy=\"-518.17\" rx=\"133.79\" ry=\"25.41\"/>\n",
       "<text text-anchor=\"start\" x=\"127.5\" y=\"-521.97\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">add_1_5</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-507.97\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "</g>\n",
       "<!-- relu_1_3&#45;&gt;add_1_5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>relu_1_3&#45;&gt;add_1_5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.73,-356.97C189.96,-367.17 198.24,-379.7 202.5,-392.71 211.35,-419.74 211.3,-429.66 202.5,-456.71 198.97,-467.55 192.69,-478.06 185.96,-487.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.83,-485.95 181.5,-492.99 187.71,-488.94 183.83,-485.95\"/>\n",
       "</g>\n",
       "<!-- conv2d_2_4&#45;&gt;add_1_5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>conv2d_2_4&#45;&gt;add_1_5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.66,-456.93C124.23,-466.61 131.45,-477.27 137.97,-486.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.97,-488.31 141.93,-492.72 140.03,-485.56 135.97,-488.31\"/>\n",
       "</g>\n",
       "<!-- batchnorm_2_6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>batchnorm_2_6</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"253,-643.62 64,-643.62 64,-579.62 253,-579.62 253,-643.62\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-629.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_2_6</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-615.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-601.42\" font-family=\"Times,serif\" font-size=\"14.00\">params: x64, x64</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-587.42\" font-family=\"Times,serif\" font-size=\"14.00\">@bn2</text>\n",
       "</g>\n",
       "<!-- add_1_5&#45;&gt;batchnorm_2_6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>add_1_5&#45;&gt;batchnorm_2_6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-543.68C158.5,-552.44 158.5,-562.55 158.5,-572.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-572.48 158.5,-579.48 160.95,-572.48 156.05,-572.48\"/>\n",
       "</g>\n",
       "<!-- relu_2_7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>relu_2_7</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"253,-729.62 64,-729.62 64,-679.62 253,-679.62 253,-729.62\"/>\n",
       "<text text-anchor=\"start\" x=\"125.5\" y=\"-715.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_2_7</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-701.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x57x57 (33.3 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-687.42\" font-family=\"Times,serif\" font-size=\"14.00\">@relu2</text>\n",
       "</g>\n",
       "<!-- batchnorm_2_6&#45;&gt;relu_2_7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>batchnorm_2_6&#45;&gt;relu_2_7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-643.68C158.5,-652.95 158.5,-663.1 158.5,-672.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-672.59 158.5,-679.59 160.95,-672.59 156.05,-672.59\"/>\n",
       "</g>\n",
       "<!-- maxpool2d_1_8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>maxpool2d_1_8</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"248.5,-815.62 68.5,-815.62 68.5,-765.62 248.5,-765.62 248.5,-815.62\"/>\n",
       "<text text-anchor=\"start\" x=\"99.5\" y=\"-801.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">maxpool2d_1_8</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-787.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x64x28x28 (8.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"131.5\" y=\"-773.42\" font-family=\"Times,serif\" font-size=\"14.00\">@pool2</text>\n",
       "</g>\n",
       "<!-- relu_2_7&#45;&gt;maxpool2d_1_8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>relu_2_7&#45;&gt;maxpool2d_1_8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-729.92C158.5,-738.8 158.5,-748.97 158.5,-758.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-758.38 158.5,-765.38 160.95,-758.38 156.05,-758.38\"/>\n",
       "</g>\n",
       "<!-- conv2d_3_9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>conv2d_3_9</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"255,-915.62 62,-915.62 62,-851.62 255,-851.62 255,-915.62\"/>\n",
       "<text text-anchor=\"start\" x=\"114\" y=\"-901.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_3_9</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-887.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"70\" y=\"-873.42\" font-family=\"Times,serif\" font-size=\"14.00\">params: 32x64x5x5, x32</text>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-859.42\" font-family=\"Times,serif\" font-size=\"14.00\">@conv3</text>\n",
       "</g>\n",
       "<!-- maxpool2d_1_8&#45;&gt;conv2d_3_9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>maxpool2d_1_8&#45;&gt;conv2d_3_9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-816.01C158.5,-824.65 158.5,-834.6 158.5,-844.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-844.3 158.5,-851.3 160.95,-844.3 156.05,-844.3\"/>\n",
       "</g>\n",
       "<!-- batchnorm_3_10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>batchnorm_3_10</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"248.5,-1015.62 68.5,-1015.62 68.5,-951.62 248.5,-951.62 248.5,-1015.62\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-1001.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_3_10</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-987.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-973.42\" font-family=\"Times,serif\" font-size=\"14.00\">params: x32, x32</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-959.42\" font-family=\"Times,serif\" font-size=\"14.00\">@bn3</text>\n",
       "</g>\n",
       "<!-- conv2d_3_9&#45;&gt;batchnorm_3_10 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>conv2d_3_9&#45;&gt;batchnorm_3_10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-915.63C158.5,-924.75 158.5,-934.83 158.5,-944.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-944.48 158.5,-951.48 160.95,-944.48 156.05,-944.48\"/>\n",
       "</g>\n",
       "<!-- relu_3_11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>relu_3_11</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"248.5,-1101.62 68.5,-1101.62 68.5,-1051.62 248.5,-1051.62 248.5,-1101.62\"/>\n",
       "<text text-anchor=\"start\" x=\"120.5\" y=\"-1087.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_3_11</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-1073.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-1059.42\" font-family=\"Times,serif\" font-size=\"14.00\">@relu3</text>\n",
       "</g>\n",
       "<!-- batchnorm_3_10&#45;&gt;relu_3_11 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>batchnorm_3_10&#45;&gt;relu_3_11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1015.68C158.5,-1024.95 158.5,-1035.1 158.5,-1044.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1044.59 158.5,-1051.59 160.95,-1044.59 156.05,-1044.59\"/>\n",
       "</g>\n",
       "<!-- conv2d_4_12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>conv2d_4_12</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"193,-1201.62 0,-1201.62 0,-1137.62 193,-1137.62 193,-1201.62\"/>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-1187.42\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_4_12</text>\n",
       "<text text-anchor=\"start\" x=\"14.5\" y=\"-1173.42\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-1159.42\" font-family=\"Times,serif\" font-size=\"14.00\">params: 32x32x5x5, x32</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-1145.42\" font-family=\"Times,serif\" font-size=\"14.00\">@conv4</text>\n",
       "</g>\n",
       "<!-- relu_3_11&#45;&gt;conv2d_4_12 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>relu_3_11&#45;&gt;conv2d_4_12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.89,-1102.01C135.77,-1110.99 128.69,-1121.38 121.96,-1131.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.75,-1130.14 117.84,-1137.3 123.8,-1132.9 119.75,-1130.14\"/>\n",
       "</g>\n",
       "<!-- add_2_13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>add_2_13</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"158.5\" cy=\"-1263.08\" rx=\"127.06\" ry=\"25.41\"/>\n",
       "<text text-anchor=\"start\" x=\"122.5\" y=\"-1266.88\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">add_2_13</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-1252.88\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "</g>\n",
       "<!-- relu_3_11&#45;&gt;add_2_13 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>relu_3_11&#45;&gt;add_2_13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.73,-1101.88C189.96,-1112.09 198.24,-1124.61 202.5,-1137.62 211.35,-1164.66 211.3,-1174.57 202.5,-1201.62 198.97,-1212.46 192.69,-1222.97 185.96,-1232.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.83,-1230.86 181.5,-1237.9 187.71,-1233.85 183.83,-1230.86\"/>\n",
       "</g>\n",
       "<!-- conv2d_4_12&#45;&gt;add_2_13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>conv2d_4_12&#45;&gt;add_2_13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.66,-1201.84C124.23,-1211.53 131.45,-1222.18 137.97,-1231.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.97,-1233.22 141.93,-1237.64 140.03,-1230.47 135.97,-1233.22\"/>\n",
       "</g>\n",
       "<!-- batchnorm_4_14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>batchnorm_4_14</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"248.5,-1388.53 68.5,-1388.53 68.5,-1324.53 248.5,-1324.53 248.5,-1388.53\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-1374.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_4_14</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-1360.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-1346.33\" font-family=\"Times,serif\" font-size=\"14.00\">params: x32, x32</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-1332.33\" font-family=\"Times,serif\" font-size=\"14.00\">@bn4</text>\n",
       "</g>\n",
       "<!-- add_2_13&#45;&gt;batchnorm_4_14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>add_2_13&#45;&gt;batchnorm_4_14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1288.59C158.5,-1297.36 158.5,-1307.46 158.5,-1317.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1317.4 158.5,-1324.4 160.95,-1317.4 156.05,-1317.4\"/>\n",
       "</g>\n",
       "<!-- relu_4_15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>relu_4_15</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"248.5,-1474.53 68.5,-1474.53 68.5,-1424.53 248.5,-1424.53 248.5,-1474.53\"/>\n",
       "<text text-anchor=\"start\" x=\"120.5\" y=\"-1460.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_4_15</text>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-1446.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x24x24 (3.0 MB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-1432.33\" font-family=\"Times,serif\" font-size=\"14.00\">@relu4</text>\n",
       "</g>\n",
       "<!-- batchnorm_4_14&#45;&gt;relu_4_15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>batchnorm_4_14&#45;&gt;relu_4_15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1388.6C158.5,-1397.86 158.5,-1408.01 158.5,-1417.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1417.5 158.5,-1424.5 160.95,-1417.5 156.05,-1417.5\"/>\n",
       "</g>\n",
       "<!-- maxpool2d_2_16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>maxpool2d_2_16</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"255.5,-1560.53 61.5,-1560.53 61.5,-1510.53 255.5,-1510.53 255.5,-1560.53\"/>\n",
       "<text text-anchor=\"start\" x=\"94.5\" y=\"-1546.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">maxpool2d_2_16</text>\n",
       "<text text-anchor=\"start\" x=\"69.5\" y=\"-1532.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x32x12x12 (756.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"131.5\" y=\"-1518.33\" font-family=\"Times,serif\" font-size=\"14.00\">@pool4</text>\n",
       "</g>\n",
       "<!-- relu_4_15&#45;&gt;maxpool2d_2_16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>relu_4_15&#45;&gt;maxpool2d_2_16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1474.83C158.5,-1483.71 158.5,-1493.88 158.5,-1503.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1503.29 158.5,-1510.29 160.95,-1503.29 156.05,-1503.29\"/>\n",
       "</g>\n",
       "<!-- conv2d_5_17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>conv2d_5_17</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"255,-1660.53 62,-1660.53 62,-1596.53 255,-1596.53 255,-1660.53\"/>\n",
       "<text text-anchor=\"start\" x=\"109\" y=\"-1646.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_5_17</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-1632.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"70\" y=\"-1618.33\" font-family=\"Times,serif\" font-size=\"14.00\">params: 16x32x5x5, x16</text>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-1604.33\" font-family=\"Times,serif\" font-size=\"14.00\">@conv5</text>\n",
       "</g>\n",
       "<!-- maxpool2d_2_16&#45;&gt;conv2d_5_17 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>maxpool2d_2_16&#45;&gt;conv2d_5_17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1560.92C158.5,-1569.56 158.5,-1579.51 158.5,-1589.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1589.21 158.5,-1596.22 160.95,-1589.22 156.05,-1589.21\"/>\n",
       "</g>\n",
       "<!-- batchnorm_5_18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>batchnorm_5_18</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"246.5,-1760.53 70.5,-1760.53 70.5,-1696.53 246.5,-1696.53 246.5,-1760.53\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-1746.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_5_18</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-1732.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-1718.33\" font-family=\"Times,serif\" font-size=\"14.00\">params: x16, x16</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-1704.33\" font-family=\"Times,serif\" font-size=\"14.00\">@bn5</text>\n",
       "</g>\n",
       "<!-- conv2d_5_17&#45;&gt;batchnorm_5_18 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>conv2d_5_17&#45;&gt;batchnorm_5_18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1660.54C158.5,-1669.66 158.5,-1679.74 158.5,-1689.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1689.39 158.5,-1696.39 160.95,-1689.39 156.05,-1689.39\"/>\n",
       "</g>\n",
       "<!-- relu_5_19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>relu_5_19</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"246.5,-1846.53 70.5,-1846.53 70.5,-1796.53 246.5,-1796.53 246.5,-1846.53\"/>\n",
       "<text text-anchor=\"start\" x=\"120.5\" y=\"-1832.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_5_19</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-1818.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-1804.33\" font-family=\"Times,serif\" font-size=\"14.00\">@relu5</text>\n",
       "</g>\n",
       "<!-- batchnorm_5_18&#45;&gt;relu_5_19 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>batchnorm_5_18&#45;&gt;relu_5_19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-1760.6C158.5,-1769.86 158.5,-1780.01 158.5,-1789.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-1789.5 158.5,-1796.5 160.95,-1789.5 156.05,-1789.5\"/>\n",
       "</g>\n",
       "<!-- conv2d_6_20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>conv2d_6_20</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"193,-1946.53 0,-1946.53 0,-1882.53 193,-1882.53 193,-1946.53\"/>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-1932.33\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">conv2d_6_20</text>\n",
       "<text text-anchor=\"start\" x=\"16.5\" y=\"-1918.33\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-1904.33\" font-family=\"Times,serif\" font-size=\"14.00\">params: 16x16x5x5, x16</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-1890.33\" font-family=\"Times,serif\" font-size=\"14.00\">@conv6</text>\n",
       "</g>\n",
       "<!-- relu_5_19&#45;&gt;conv2d_6_20 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>relu_5_19&#45;&gt;conv2d_6_20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.89,-1846.92C135.77,-1855.9 128.69,-1866.29 121.96,-1876.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.75,-1875.05 117.84,-1882.22 123.8,-1877.81 119.75,-1875.05\"/>\n",
       "</g>\n",
       "<!-- add_3_21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>add_3_21</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"158.5\" cy=\"-2007.99\" rx=\"124.4\" ry=\"25.41\"/>\n",
       "<text text-anchor=\"start\" x=\"122.5\" y=\"-2011.79\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">add_3_21</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-1997.79\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "</g>\n",
       "<!-- relu_5_19&#45;&gt;add_3_21 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>relu_5_19&#45;&gt;add_3_21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.73,-1846.79C189.96,-1857 198.24,-1869.52 202.5,-1882.53 211.35,-1909.57 211.3,-1919.49 202.5,-1946.53 198.97,-1957.37 192.69,-1967.88 185.96,-1977.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.83,-1975.77 181.5,-1982.81 187.71,-1978.76 183.83,-1975.77\"/>\n",
       "</g>\n",
       "<!-- conv2d_6_20&#45;&gt;add_3_21 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>conv2d_6_20&#45;&gt;add_3_21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.66,-1946.75C124.23,-1956.44 131.45,-1967.09 137.97,-1976.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.97,-1978.13 141.93,-1982.55 140.03,-1975.38 135.97,-1978.13\"/>\n",
       "</g>\n",
       "<!-- batchnorm_6_22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>batchnorm_6_22</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"246.5,-2133.45 70.5,-2133.45 70.5,-2069.45 246.5,-2069.45 246.5,-2133.45\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-2119.25\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">batchnorm_6_22</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-2105.25\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-2091.25\" font-family=\"Times,serif\" font-size=\"14.00\">params: x16, x16</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-2077.25\" font-family=\"Times,serif\" font-size=\"14.00\">@bn6</text>\n",
       "</g>\n",
       "<!-- add_3_21&#45;&gt;batchnorm_6_22 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>add_3_21&#45;&gt;batchnorm_6_22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2033.5C158.5,-2042.27 158.5,-2052.38 158.5,-2062.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2062.31 158.5,-2069.31 160.95,-2062.31 156.05,-2062.31\"/>\n",
       "</g>\n",
       "<!-- relu_6_23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>relu_6_23</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"246.5,-2219.45 70.5,-2219.45 70.5,-2169.45 246.5,-2169.45 246.5,-2219.45\"/>\n",
       "<text text-anchor=\"start\" x=\"120.5\" y=\"-2205.25\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">relu_6_23</text>\n",
       "<text text-anchor=\"start\" x=\"78.5\" y=\"-2191.25\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x8x8 (168.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-2177.25\" font-family=\"Times,serif\" font-size=\"14.00\">@relu6</text>\n",
       "</g>\n",
       "<!-- batchnorm_6_22&#45;&gt;relu_6_23 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>batchnorm_6_22&#45;&gt;relu_6_23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2133.51C158.5,-2142.77 158.5,-2152.93 158.5,-2162.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2162.42 158.5,-2169.42 160.95,-2162.42 156.05,-2162.42\"/>\n",
       "</g>\n",
       "<!-- maxpool2d_3_24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>maxpool2d_3_24</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"242,-2305.45 75,-2305.45 75,-2255.45 242,-2255.45 242,-2305.45\"/>\n",
       "<text text-anchor=\"start\" x=\"94.5\" y=\"-2291.25\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">maxpool2d_3_24</text>\n",
       "<text text-anchor=\"start\" x=\"83\" y=\"-2277.25\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x4x4 (42.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"131.5\" y=\"-2263.25\" font-family=\"Times,serif\" font-size=\"14.00\">@pool6</text>\n",
       "</g>\n",
       "<!-- relu_6_23&#45;&gt;maxpool2d_3_24 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>relu_6_23&#45;&gt;maxpool2d_3_24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2219.74C158.5,-2228.62 158.5,-2238.8 158.5,-2248.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2248.2 158.5,-2255.2 160.95,-2248.2 156.05,-2248.2\"/>\n",
       "</g>\n",
       "<!-- dropout_1_25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>dropout_1_25</title>\n",
       "<polygon fill=\"white\" stroke=\"black\" points=\"242,-2391.45 75,-2391.45 75,-2341.45 242,-2341.45 242,-2391.45\"/>\n",
       "<text text-anchor=\"start\" x=\"105.5\" y=\"-2377.25\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">dropout_1_25</text>\n",
       "<text text-anchor=\"start\" x=\"83\" y=\"-2363.25\" font-family=\"Times,serif\" font-size=\"14.00\">42x16x4x4 (42.2 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-2349.25\" font-family=\"Times,serif\" font-size=\"14.00\">@drop7</text>\n",
       "</g>\n",
       "<!-- maxpool2d_3_24&#45;&gt;dropout_1_25 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>maxpool2d_3_24&#45;&gt;dropout_1_25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2305.74C158.5,-2314.62 158.5,-2324.8 158.5,-2334.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2334.2 158.5,-2341.2 160.95,-2334.2 156.05,-2334.2\"/>\n",
       "</g>\n",
       "<!-- view_1_26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>view_1_26</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"158.5\" cy=\"-2452.9\" rx=\"100.32\" ry=\"25.41\"/>\n",
       "<text text-anchor=\"start\" x=\"119.5\" y=\"-2456.7\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">view_1_26</text>\n",
       "<text text-anchor=\"start\" x=\"95.5\" y=\"-2442.7\" font-family=\"Times,serif\" font-size=\"14.00\">42x256 (42.1 KB)</text>\n",
       "</g>\n",
       "<!-- dropout_1_25&#45;&gt;view_1_26 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>dropout_1_25&#45;&gt;view_1_26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2391.87C158.5,-2400.64 158.5,-2410.65 158.5,-2419.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2420.24 158.5,-2427.24 160.95,-2420.24 156.05,-2420.24\"/>\n",
       "</g>\n",
       "<!-- linear_1_27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>linear_1_27</title>\n",
       "<polygon fill=\"#e6e6e6\" stroke=\"black\" points=\"242,-2578.36 75,-2578.36 75,-2514.36 242,-2514.36 242,-2578.36\"/>\n",
       "<text text-anchor=\"start\" x=\"113.5\" y=\"-2564.16\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">linear_1_27</text>\n",
       "<text text-anchor=\"start\" x=\"104.5\" y=\"-2550.16\" font-family=\"Times,serif\" font-size=\"14.00\">42x10 (1.8 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"83\" y=\"-2536.16\" font-family=\"Times,serif\" font-size=\"14.00\">params: 10x256, x10</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-2522.16\" font-family=\"Times,serif\" font-size=\"14.00\">@lin7</text>\n",
       "</g>\n",
       "<!-- view_1_26&#45;&gt;linear_1_27 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>view_1_26&#45;&gt;linear_1_27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2478.41C158.5,-2487.18 158.5,-2497.29 158.5,-2506.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2507.22 158.5,-2514.22 160.95,-2507.22 156.05,-2507.22\"/>\n",
       "</g>\n",
       "<!-- output_1 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>output_1</title>\n",
       "<ellipse fill=\"#ff9999\" stroke=\"black\" cx=\"158.5\" cy=\"-2649.71\" rx=\"87.86\" ry=\"35.21\"/>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2660.51\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">output_1</text>\n",
       "<text text-anchor=\"start\" x=\"104.5\" y=\"-2646.51\" font-family=\"Times,serif\" font-size=\"14.00\">42x10 (1.8 KB)</text>\n",
       "<text text-anchor=\"start\" x=\"127.5\" y=\"-2632.51\" font-family=\"Times,serif\" font-size=\"14.00\">@output</text>\n",
       "</g>\n",
       "<!-- linear_1_27&#45;&gt;output_1 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>linear_1_27&#45;&gt;output_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.5,-2578.59C158.5,-2587.59 158.5,-2597.54 158.5,-2607.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.05,-2607.22 158.5,-2614.22 160.95,-2607.23 156.05,-2607.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f5753dd1fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log of DeepCNN forward pass:\n",
      "\tRandom seed: 3955512425\n",
      "\tTime elapsed: 8.296s (8.128s spent logging)\n",
      "\tStructure:\n",
      "\t\t- purely feedforward, no recurrence\n",
      "\t\t- with branching\n",
      "\t\t- no conditional (if-then) branching\n",
      "\t\t- contains 12 buffer layers\n",
      "\t\t- 23 total modules\n",
      "\tTensor info:\n",
      "\t\t- 41 total tensors (265.9 MB) computed in forward pass.\n",
      "\t\t- 41 tensors (265.9 MB) with saved activations.\n",
      "\tParameters: 13 parameter operations (213930 params total; 838.8 KB)\n",
      "\tModule Hierarchy:\n",
      "\t\tconv1\n",
      "\t\tbn1\n",
      "\t\trelu1\n",
      "\t\tconv2\n",
      "\t\tbn2\n",
      "\t\trelu2\n",
      "\t\tpool2\n",
      "\t\tconv3\n",
      "\t\tbn3\n",
      "\t\trelu3\n",
      "\t\tconv4\n",
      "\t\tbn4\n",
      "\t\trelu4\n",
      "\t\tpool4\n",
      "\t\tconv5\n",
      "\t\tbn5\n",
      "\t\trelu5\n",
      "\t\tconv6\n",
      "\t\tbn6\n",
      "\t\trelu6\n",
      "\t\tpool6\n",
      "\t\tdrop7\n",
      "\t\tlin7\n",
      "\tLayers (all have saved activations):\n",
      "\t\t  (0) input_1 \n",
      "\t\t  (1) conv2d_1_1 \n",
      "\t\t  (2) buffer_1 \n",
      "\t\t  (3) buffer_2 \n",
      "\t\t  (4) batchnorm_1_2 \n",
      "\t\t  (5) relu_1_3 \n",
      "\t\t  (6) conv2d_2_4 \n",
      "\t\t  (7) add_1_5 \n",
      "\t\t  (8) buffer_3 \n",
      "\t\t  (9) buffer_4 \n",
      "\t\t  (10) batchnorm_2_6 \n",
      "\t\t  (11) relu_2_7 \n",
      "\t\t  (12) maxpool2d_1_8 \n",
      "\t\t  (13) conv2d_3_9 \n",
      "\t\t  (14) buffer_5 \n",
      "\t\t  (15) buffer_6 \n",
      "\t\t  (16) batchnorm_3_10 \n",
      "\t\t  (17) relu_3_11 \n",
      "\t\t  (18) conv2d_4_12 \n",
      "\t\t  (19) add_2_13 \n",
      "\t\t  (20) buffer_7 \n",
      "\t\t  (21) buffer_8 \n",
      "\t\t  (22) batchnorm_4_14 \n",
      "\t\t  (23) relu_4_15 \n",
      "\t\t  (24) maxpool2d_2_16 \n",
      "\t\t  (25) conv2d_5_17 \n",
      "\t\t  (26) buffer_9 \n",
      "\t\t  (27) buffer_10 \n",
      "\t\t  (28) batchnorm_5_18 \n",
      "\t\t  (29) relu_5_19 \n",
      "\t\t  (30) conv2d_6_20 \n",
      "\t\t  (31) add_3_21 \n",
      "\t\t  (32) buffer_11 \n",
      "\t\t  (33) buffer_12 \n",
      "\t\t  (34) batchnorm_6_22 \n",
      "\t\t  (35) relu_6_23 \n",
      "\t\t  (36) maxpool2d_3_24 \n",
      "\t\t  (37) dropout_1_25 \n",
      "\t\t  (38) view_1_26 \n",
      "\t\t  (39) linear_1_27 \n",
      "\t\t  (40) output_1 \n"
     ]
    }
   ],
   "source": [
    "import torchlens as tl\n",
    "model_history = tl.log_forward_pass(model, dummy_img, layers_to_save='all', vis_opt='rolled')\n",
    "print(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d82760",
   "metadata": {},
   "source": [
    "### Initialize the model and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b095176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.model_selection import train_test_split\\n\\n# Split dataset into training and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Create data loaders for training and validation sets\\ntrain_dataset = MyDataset(X_train, y_train)\\nval_dataset = MyDataset(X_val, y_val)\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "val_dataset = MyDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37dce276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([50, 3, 64, 64])\n",
      "Labels batch shape: torch.Size([50, 10])\n",
      "torch.Size([20, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "DeepCNN                                  --\n",
       "Conv2d: 1-1                            12,352\n",
       "BatchNorm2d: 1-2                       128\n",
       "ReLU: 1-3                              --\n",
       "Conv2d: 1-4                            102,464\n",
       "BatchNorm2d: 1-5                       128\n",
       "ReLU: 1-6                              --\n",
       "MaxPool2d: 1-7                         --\n",
       "Conv2d: 1-8                            51,232\n",
       "BatchNorm2d: 1-9                       64\n",
       "ReLU: 1-10                             --\n",
       "Conv2d: 1-11                           25,632\n",
       "BatchNorm2d: 1-12                      64\n",
       "ReLU: 1-13                             --\n",
       "MaxPool2d: 1-14                        --\n",
       "Conv2d: 1-15                           12,816\n",
       "BatchNorm2d: 1-16                      32\n",
       "ReLU: 1-17                             --\n",
       "Conv2d: 1-18                           6,416\n",
       "BatchNorm2d: 1-19                      32\n",
       "ReLU: 1-20                             --\n",
       "MaxPool2d: 1-21                        --\n",
       "Dropout: 1-22                          --\n",
       "Linear: 1-23                           2,570\n",
       "=================================================================\n",
       "Total params: 213,930\n",
       "Trainable params: 213,930\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and validation datasets\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 128\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "model = get_model(num_classes) # define the model\n",
    "# model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "image = torch.randn(20, 3, 64, 64) # create dummy image\n",
    "output = model(image)\n",
    "\n",
    "print(model(image).shape) # show the output of one batch of images\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model) # display summary of the model and number of trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520830e6",
   "metadata": {},
   "source": [
    "### Send the model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76203502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCNN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(8, 8), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu4): ReLU()\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu5): ReLU()\n",
       "  (conv6): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu6): ReLU()\n",
       "  (pool6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop7): Dropout(p=0.05, inplace=False)\n",
       "  (lin7): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8b5dc",
   "metadata": {},
   "source": [
    "### Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb08e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "\n",
    "            # Compute loss and its gradients\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            \n",
    "\n",
    "            # Backpropagation step\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y.argmax(1)).sum().item()\n",
    "\n",
    "            # Display progress\n",
    "            if batch % 5 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"Epoch {epoch+1}, batch {batch+1}/{len(train_loader)}, loss: {loss:.4f}\")\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        print(f\"Epoch {epoch+1}, train loss: {train_loss:.4f}, train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, y) in enumerate(val_loader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(pred.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y.argmax(1)).sum().item()\n",
    "            val_loss = running_loss / len(val_loader)\n",
    "            val_acc = 100 * correct / total\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            print(f\"Epoch {epoch+1}, val loss: {val_loss:.4f}, val accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "            # # Save best model\n",
    "            # if val_acc > best_val_acc:\n",
    "            #     best_val_acc = val_acc\n",
    "            #     torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    return train_losses, train_accs, val_losses, val_accs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f224c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, batch 1/72, loss: 2.5064\n",
      "Epoch 1, batch 6/72, loss: 2.2425\n",
      "Epoch 1, batch 11/72, loss: 2.0936\n",
      "Epoch 1, batch 16/72, loss: 1.7722\n",
      "Epoch 1, batch 21/72, loss: 1.7549\n",
      "Epoch 1, batch 26/72, loss: 1.5961\n",
      "Epoch 1, batch 31/72, loss: 1.5253\n",
      "Epoch 1, batch 36/72, loss: 1.6038\n",
      "Epoch 1, batch 41/72, loss: 1.4303\n",
      "Epoch 1, batch 46/72, loss: 1.4325\n",
      "Epoch 1, batch 51/72, loss: 1.3590\n",
      "Epoch 1, batch 56/72, loss: 1.1409\n",
      "Epoch 1, batch 61/72, loss: 1.3270\n",
      "Epoch 1, batch 66/72, loss: 1.2417\n",
      "Epoch 1, batch 71/72, loss: 1.3910\n",
      "Epoch 1, train loss: 1.5924, train accuracy: 45.13%\n",
      "Epoch 1, val loss: 1.1638, val accuracy: 60.81%\n",
      "Epoch 2, batch 1/72, loss: 1.0809\n",
      "Epoch 2, batch 6/72, loss: 1.1146\n",
      "Epoch 2, batch 11/72, loss: 1.1416\n",
      "Epoch 2, batch 16/72, loss: 1.0619\n",
      "Epoch 2, batch 21/72, loss: 1.0641\n",
      "Epoch 2, batch 26/72, loss: 0.9849\n",
      "Epoch 2, batch 31/72, loss: 1.0218\n",
      "Epoch 2, batch 36/72, loss: 1.0533\n",
      "Epoch 2, batch 41/72, loss: 0.8618\n",
      "Epoch 2, batch 46/72, loss: 1.0434\n",
      "Epoch 2, batch 51/72, loss: 0.9109\n",
      "Epoch 2, batch 56/72, loss: 0.9526\n",
      "Epoch 2, batch 61/72, loss: 0.7302\n",
      "Epoch 2, batch 66/72, loss: 0.9107\n",
      "Epoch 2, batch 71/72, loss: 0.9970\n",
      "Epoch 2, train loss: 0.9926, train accuracy: 67.95%\n",
      "Epoch 2, val loss: 0.8520, val accuracy: 72.92%\n",
      "Epoch 3, batch 1/72, loss: 0.8510\n",
      "Epoch 3, batch 6/72, loss: 0.8641\n",
      "Epoch 3, batch 11/72, loss: 0.8229\n",
      "Epoch 3, batch 16/72, loss: 0.7429\n",
      "Epoch 3, batch 21/72, loss: 0.8098\n",
      "Epoch 3, batch 26/72, loss: 0.6798\n",
      "Epoch 3, batch 31/72, loss: 0.7051\n",
      "Epoch 3, batch 36/72, loss: 0.7710\n",
      "Epoch 3, batch 41/72, loss: 0.8393\n",
      "Epoch 3, batch 46/72, loss: 0.8155\n",
      "Epoch 3, batch 51/72, loss: 0.8046\n",
      "Epoch 3, batch 56/72, loss: 0.7110\n",
      "Epoch 3, batch 61/72, loss: 0.7036\n",
      "Epoch 3, batch 66/72, loss: 0.7051\n",
      "Epoch 3, batch 71/72, loss: 0.7795\n",
      "Epoch 3, train loss: 0.7879, train accuracy: 73.77%\n",
      "Epoch 3, val loss: 0.7893, val accuracy: 73.22%\n",
      "Epoch 4, batch 1/72, loss: 0.6812\n",
      "Epoch 4, batch 6/72, loss: 0.8144\n",
      "Epoch 4, batch 11/72, loss: 0.7224\n",
      "Epoch 4, batch 16/72, loss: 0.6306\n",
      "Epoch 4, batch 21/72, loss: 0.7190\n",
      "Epoch 4, batch 26/72, loss: 0.7642\n",
      "Epoch 4, batch 31/72, loss: 0.6574\n",
      "Epoch 4, batch 36/72, loss: 0.5343\n",
      "Epoch 4, batch 41/72, loss: 0.6409\n",
      "Epoch 4, batch 46/72, loss: 0.6859\n",
      "Epoch 4, batch 51/72, loss: 0.5714\n",
      "Epoch 4, batch 56/72, loss: 0.5767\n",
      "Epoch 4, batch 61/72, loss: 0.7795\n",
      "Epoch 4, batch 66/72, loss: 0.4765\n",
      "Epoch 4, batch 71/72, loss: 0.6580\n",
      "Epoch 4, train loss: 0.6615, train accuracy: 77.71%\n",
      "Epoch 4, val loss: 0.6773, val accuracy: 76.91%\n",
      "Epoch 5, batch 1/72, loss: 0.5938\n",
      "Epoch 5, batch 6/72, loss: 0.5322\n",
      "Epoch 5, batch 11/72, loss: 0.5350\n",
      "Epoch 5, batch 16/72, loss: 0.6100\n",
      "Epoch 5, batch 21/72, loss: 0.5812\n",
      "Epoch 5, batch 26/72, loss: 0.5848\n",
      "Epoch 5, batch 31/72, loss: 0.6322\n",
      "Epoch 5, batch 36/72, loss: 0.6174\n",
      "Epoch 5, batch 41/72, loss: 0.5453\n",
      "Epoch 5, batch 46/72, loss: 0.6747\n",
      "Epoch 5, batch 51/72, loss: 0.5045\n",
      "Epoch 5, batch 56/72, loss: 0.6742\n",
      "Epoch 5, batch 61/72, loss: 0.5525\n",
      "Epoch 5, batch 66/72, loss: 0.6096\n",
      "Epoch 5, batch 71/72, loss: 0.6350\n",
      "Epoch 5, train loss: 0.6088, train accuracy: 79.31%\n",
      "Epoch 5, val loss: 0.6750, val accuracy: 76.39%\n",
      "Epoch 6, batch 1/72, loss: 0.5698\n",
      "Epoch 6, batch 6/72, loss: 0.6087\n",
      "Epoch 6, batch 11/72, loss: 0.6377\n",
      "Epoch 6, batch 16/72, loss: 0.6265\n",
      "Epoch 6, batch 21/72, loss: 0.5719\n",
      "Epoch 6, batch 26/72, loss: 0.5653\n",
      "Epoch 6, batch 31/72, loss: 0.5628\n",
      "Epoch 6, batch 36/72, loss: 0.5329\n",
      "Epoch 6, batch 41/72, loss: 0.5599\n",
      "Epoch 6, batch 46/72, loss: 0.5828\n",
      "Epoch 6, batch 51/72, loss: 0.5905\n",
      "Epoch 6, batch 56/72, loss: 0.5397\n",
      "Epoch 6, batch 61/72, loss: 0.6364\n",
      "Epoch 6, batch 66/72, loss: 0.5561\n",
      "Epoch 6, batch 71/72, loss: 0.5959\n",
      "Epoch 6, train loss: 0.5549, train accuracy: 81.40%\n",
      "Epoch 6, val loss: 0.6150, val accuracy: 78.78%\n",
      "Epoch 7, batch 1/72, loss: 0.4449\n",
      "Epoch 7, batch 6/72, loss: 0.3740\n",
      "Epoch 7, batch 11/72, loss: 0.4959\n",
      "Epoch 7, batch 16/72, loss: 0.5896\n",
      "Epoch 7, batch 21/72, loss: 0.5272\n",
      "Epoch 7, batch 26/72, loss: 0.5199\n",
      "Epoch 7, batch 31/72, loss: 0.4249\n",
      "Epoch 7, batch 36/72, loss: 0.5781\n",
      "Epoch 7, batch 41/72, loss: 0.4998\n",
      "Epoch 7, batch 46/72, loss: 0.4261\n",
      "Epoch 7, batch 51/72, loss: 0.5749\n",
      "Epoch 7, batch 56/72, loss: 0.5287\n",
      "Epoch 7, batch 61/72, loss: 0.5656\n",
      "Epoch 7, batch 66/72, loss: 0.5887\n",
      "Epoch 7, batch 71/72, loss: 0.4597\n",
      "Epoch 7, train loss: 0.5159, train accuracy: 82.53%\n",
      "Epoch 7, val loss: 0.5873, val accuracy: 79.69%\n",
      "Epoch 8, batch 1/72, loss: 0.4376\n",
      "Epoch 8, batch 6/72, loss: 0.5185\n",
      "Epoch 8, batch 11/72, loss: 0.4267\n",
      "Epoch 8, batch 16/72, loss: 0.4106\n",
      "Epoch 8, batch 21/72, loss: 0.4587\n",
      "Epoch 8, batch 26/72, loss: 0.3903\n",
      "Epoch 8, batch 31/72, loss: 0.5051\n",
      "Epoch 8, batch 36/72, loss: 0.3655\n",
      "Epoch 8, batch 41/72, loss: 0.4339\n",
      "Epoch 8, batch 46/72, loss: 0.4184\n",
      "Epoch 8, batch 51/72, loss: 0.5498\n",
      "Epoch 8, batch 56/72, loss: 0.5235\n",
      "Epoch 8, batch 61/72, loss: 0.4002\n",
      "Epoch 8, batch 66/72, loss: 0.3877\n",
      "Epoch 8, batch 71/72, loss: 0.5788\n",
      "Epoch 8, train loss: 0.4808, train accuracy: 83.49%\n",
      "Epoch 8, val loss: 0.5552, val accuracy: 80.82%\n",
      "Epoch 9, batch 1/72, loss: 0.4795\n",
      "Epoch 9, batch 6/72, loss: 0.4174\n",
      "Epoch 9, batch 11/72, loss: 0.3747\n",
      "Epoch 9, batch 16/72, loss: 0.5956\n",
      "Epoch 9, batch 21/72, loss: 0.4450\n",
      "Epoch 9, batch 26/72, loss: 0.4498\n",
      "Epoch 9, batch 31/72, loss: 0.4443\n",
      "Epoch 9, batch 36/72, loss: 0.4805\n",
      "Epoch 9, batch 41/72, loss: 0.3507\n",
      "Epoch 9, batch 46/72, loss: 0.4785\n",
      "Epoch 9, batch 51/72, loss: 0.5001\n",
      "Epoch 9, batch 56/72, loss: 0.4025\n",
      "Epoch 9, batch 61/72, loss: 0.3916\n",
      "Epoch 9, batch 66/72, loss: 0.4720\n",
      "Epoch 9, batch 71/72, loss: 0.5635\n",
      "Epoch 9, train loss: 0.4566, train accuracy: 84.63%\n",
      "Epoch 9, val loss: 0.5210, val accuracy: 82.38%\n",
      "Epoch 10, batch 1/72, loss: 0.4189\n",
      "Epoch 10, batch 6/72, loss: 0.3547\n",
      "Epoch 10, batch 11/72, loss: 0.4641\n",
      "Epoch 10, batch 16/72, loss: 0.2957\n",
      "Epoch 10, batch 21/72, loss: 0.3760\n",
      "Epoch 10, batch 26/72, loss: 0.2980\n",
      "Epoch 10, batch 31/72, loss: 0.3907\n",
      "Epoch 10, batch 36/72, loss: 0.4023\n",
      "Epoch 10, batch 41/72, loss: 0.5101\n",
      "Epoch 10, batch 46/72, loss: 0.4896\n",
      "Epoch 10, batch 51/72, loss: 0.4200\n",
      "Epoch 10, batch 56/72, loss: 0.3863\n",
      "Epoch 10, batch 61/72, loss: 0.4862\n",
      "Epoch 10, batch 66/72, loss: 0.4267\n",
      "Epoch 10, batch 71/72, loss: 0.5013\n",
      "Epoch 10, train loss: 0.4121, train accuracy: 86.17%\n",
      "Epoch 10, val loss: 0.5013, val accuracy: 83.33%\n",
      "Epoch 11, batch 1/72, loss: 0.4321\n",
      "Epoch 11, batch 6/72, loss: 0.3114\n",
      "Epoch 11, batch 11/72, loss: 0.3441\n",
      "Epoch 11, batch 16/72, loss: 0.4214\n",
      "Epoch 11, batch 21/72, loss: 0.4154\n",
      "Epoch 11, batch 26/72, loss: 0.3572\n",
      "Epoch 11, batch 31/72, loss: 0.2517\n",
      "Epoch 11, batch 36/72, loss: 0.3476\n",
      "Epoch 11, batch 41/72, loss: 0.2972\n",
      "Epoch 11, batch 46/72, loss: 0.3535\n",
      "Epoch 11, batch 51/72, loss: 0.4355\n",
      "Epoch 11, batch 56/72, loss: 0.3466\n",
      "Epoch 11, batch 61/72, loss: 0.3610\n",
      "Epoch 11, batch 66/72, loss: 0.4326\n",
      "Epoch 11, batch 71/72, loss: 0.4060\n",
      "Epoch 11, train loss: 0.3746, train accuracy: 87.40%\n",
      "Epoch 11, val loss: 0.5164, val accuracy: 82.60%\n",
      "Epoch 12, batch 1/72, loss: 0.3677\n",
      "Epoch 12, batch 6/72, loss: 0.3793\n",
      "Epoch 12, batch 11/72, loss: 0.4042\n",
      "Epoch 12, batch 16/72, loss: 0.3546\n",
      "Epoch 12, batch 21/72, loss: 0.2521\n",
      "Epoch 12, batch 26/72, loss: 0.3958\n",
      "Epoch 12, batch 31/72, loss: 0.4913\n",
      "Epoch 12, batch 36/72, loss: 0.4308\n",
      "Epoch 12, batch 41/72, loss: 0.2936\n",
      "Epoch 12, batch 46/72, loss: 0.3456\n",
      "Epoch 12, batch 51/72, loss: 0.3899\n",
      "Epoch 12, batch 56/72, loss: 0.3736\n",
      "Epoch 12, batch 61/72, loss: 0.4063\n",
      "Epoch 12, batch 66/72, loss: 0.3441\n",
      "Epoch 12, batch 71/72, loss: 0.4580\n",
      "Epoch 12, train loss: 0.3656, train accuracy: 87.73%\n",
      "Epoch 12, val loss: 0.4595, val accuracy: 84.11%\n",
      "Epoch 13, batch 1/72, loss: 0.3593\n",
      "Epoch 13, batch 6/72, loss: 0.3392\n",
      "Epoch 13, batch 11/72, loss: 0.3517\n",
      "Epoch 13, batch 16/72, loss: 0.2887\n",
      "Epoch 13, batch 21/72, loss: 0.4127\n",
      "Epoch 13, batch 26/72, loss: 0.2410\n",
      "Epoch 13, batch 31/72, loss: 0.4093\n",
      "Epoch 13, batch 36/72, loss: 0.3395\n",
      "Epoch 13, batch 41/72, loss: 0.3191\n",
      "Epoch 13, batch 46/72, loss: 0.3114\n",
      "Epoch 13, batch 51/72, loss: 0.2583\n",
      "Epoch 13, batch 56/72, loss: 0.2929\n",
      "Epoch 13, batch 61/72, loss: 0.3099\n",
      "Epoch 13, batch 66/72, loss: 0.3709\n",
      "Epoch 13, batch 71/72, loss: 0.2681\n",
      "Epoch 13, train loss: 0.3367, train accuracy: 88.48%\n",
      "Epoch 13, val loss: 0.4676, val accuracy: 83.98%\n",
      "Epoch 14, batch 1/72, loss: 0.3147\n",
      "Epoch 14, batch 6/72, loss: 0.1952\n",
      "Epoch 14, batch 11/72, loss: 0.2593\n",
      "Epoch 14, batch 16/72, loss: 0.2454\n",
      "Epoch 14, batch 21/72, loss: 0.3141\n",
      "Epoch 14, batch 26/72, loss: 0.2662\n",
      "Epoch 14, batch 31/72, loss: 0.3110\n",
      "Epoch 14, batch 36/72, loss: 0.2787\n",
      "Epoch 14, batch 41/72, loss: 0.2466\n",
      "Epoch 14, batch 46/72, loss: 0.2872\n",
      "Epoch 14, batch 51/72, loss: 0.3907\n",
      "Epoch 14, batch 56/72, loss: 0.3161\n",
      "Epoch 14, batch 61/72, loss: 0.2035\n",
      "Epoch 14, batch 66/72, loss: 0.3155\n",
      "Epoch 14, batch 71/72, loss: 0.3943\n",
      "Epoch 14, train loss: 0.3072, train accuracy: 90.04%\n",
      "Epoch 14, val loss: 0.4621, val accuracy: 84.33%\n",
      "Epoch 15, batch 1/72, loss: 0.2587\n",
      "Epoch 15, batch 6/72, loss: 0.2854\n",
      "Epoch 15, batch 11/72, loss: 0.3920\n",
      "Epoch 15, batch 16/72, loss: 0.3249\n",
      "Epoch 15, batch 21/72, loss: 0.3917\n",
      "Epoch 15, batch 26/72, loss: 0.3405\n",
      "Epoch 15, batch 31/72, loss: 0.3285\n",
      "Epoch 15, batch 36/72, loss: 0.3125\n",
      "Epoch 15, batch 41/72, loss: 0.1887\n",
      "Epoch 15, batch 46/72, loss: 0.2711\n",
      "Epoch 15, batch 51/72, loss: 0.2223\n",
      "Epoch 15, batch 56/72, loss: 0.2848\n",
      "Epoch 15, batch 61/72, loss: 0.1687\n",
      "Epoch 15, batch 66/72, loss: 0.3434\n",
      "Epoch 15, batch 71/72, loss: 0.3611\n",
      "Epoch 15, train loss: 0.2936, train accuracy: 90.11%\n",
      "Epoch 15, val loss: 0.4344, val accuracy: 85.50%\n",
      "Epoch 16, batch 1/72, loss: 0.3282\n",
      "Epoch 16, batch 6/72, loss: 0.2150\n",
      "Epoch 16, batch 11/72, loss: 0.3401\n",
      "Epoch 16, batch 16/72, loss: 0.3781\n",
      "Epoch 16, batch 21/72, loss: 0.3083\n",
      "Epoch 16, batch 26/72, loss: 0.3141\n",
      "Epoch 16, batch 31/72, loss: 0.3934\n",
      "Epoch 16, batch 36/72, loss: 0.2304\n",
      "Epoch 16, batch 41/72, loss: 0.1793\n",
      "Epoch 16, batch 46/72, loss: 0.2225\n",
      "Epoch 16, batch 51/72, loss: 0.1878\n",
      "Epoch 16, batch 56/72, loss: 0.2257\n",
      "Epoch 16, batch 61/72, loss: 0.2363\n",
      "Epoch 16, batch 66/72, loss: 0.1865\n",
      "Epoch 16, batch 71/72, loss: 0.2403\n",
      "Epoch 16, train loss: 0.2727, train accuracy: 90.99%\n",
      "Epoch 16, val loss: 0.4043, val accuracy: 86.33%\n",
      "Epoch 17, batch 1/72, loss: 0.2213\n",
      "Epoch 17, batch 6/72, loss: 0.2672\n",
      "Epoch 17, batch 11/72, loss: 0.2448\n",
      "Epoch 17, batch 16/72, loss: 0.1874\n",
      "Epoch 17, batch 21/72, loss: 0.2958\n",
      "Epoch 17, batch 26/72, loss: 0.2729\n",
      "Epoch 17, batch 31/72, loss: 0.2372\n",
      "Epoch 17, batch 36/72, loss: 0.2593\n",
      "Epoch 17, batch 41/72, loss: 0.1861\n",
      "Epoch 17, batch 46/72, loss: 0.1989\n",
      "Epoch 17, batch 51/72, loss: 0.2331\n",
      "Epoch 17, batch 56/72, loss: 0.3293\n",
      "Epoch 17, batch 61/72, loss: 0.1957\n",
      "Epoch 17, batch 66/72, loss: 0.2622\n",
      "Epoch 17, batch 71/72, loss: 0.3271\n",
      "Epoch 17, train loss: 0.2564, train accuracy: 91.50%\n",
      "Epoch 17, val loss: 0.4061, val accuracy: 87.15%\n",
      "Epoch 18, batch 1/72, loss: 0.2140\n",
      "Epoch 18, batch 6/72, loss: 0.3378\n",
      "Epoch 18, batch 11/72, loss: 0.3047\n",
      "Epoch 18, batch 16/72, loss: 0.1666\n",
      "Epoch 18, batch 21/72, loss: 0.2626\n",
      "Epoch 18, batch 26/72, loss: 0.2756\n",
      "Epoch 18, batch 31/72, loss: 0.3630\n",
      "Epoch 18, batch 36/72, loss: 0.3295\n",
      "Epoch 18, batch 41/72, loss: 0.1656\n",
      "Epoch 18, batch 46/72, loss: 0.2360\n",
      "Epoch 18, batch 51/72, loss: 0.3551\n",
      "Epoch 18, batch 56/72, loss: 0.3564\n",
      "Epoch 18, batch 61/72, loss: 0.2403\n",
      "Epoch 18, batch 66/72, loss: 0.1876\n",
      "Epoch 18, batch 71/72, loss: 0.2428\n",
      "Epoch 18, train loss: 0.2583, train accuracy: 91.51%\n",
      "Epoch 18, val loss: 0.4365, val accuracy: 85.20%\n",
      "Epoch 19, batch 1/72, loss: 0.2422\n",
      "Epoch 19, batch 6/72, loss: 0.3710\n",
      "Epoch 19, batch 11/72, loss: 0.1935\n",
      "Epoch 19, batch 16/72, loss: 0.2139\n",
      "Epoch 19, batch 21/72, loss: 0.2152\n",
      "Epoch 19, batch 26/72, loss: 0.2803\n",
      "Epoch 19, batch 31/72, loss: 0.2071\n",
      "Epoch 19, batch 36/72, loss: 0.2324\n",
      "Epoch 19, batch 41/72, loss: 0.2736\n",
      "Epoch 19, batch 46/72, loss: 0.1452\n",
      "Epoch 19, batch 51/72, loss: 0.2617\n",
      "Epoch 19, batch 56/72, loss: 0.2234\n",
      "Epoch 19, batch 61/72, loss: 0.2893\n",
      "Epoch 19, batch 66/72, loss: 0.1728\n",
      "Epoch 19, batch 71/72, loss: 0.2992\n",
      "Epoch 19, train loss: 0.2361, train accuracy: 92.18%\n",
      "Epoch 19, val loss: 0.4328, val accuracy: 85.63%\n",
      "Epoch 20, batch 1/72, loss: 0.1763\n",
      "Epoch 20, batch 6/72, loss: 0.2061\n",
      "Epoch 20, batch 11/72, loss: 0.1696\n",
      "Epoch 20, batch 16/72, loss: 0.1759\n",
      "Epoch 20, batch 21/72, loss: 0.1805\n",
      "Epoch 20, batch 26/72, loss: 0.2868\n",
      "Epoch 20, batch 31/72, loss: 0.2137\n",
      "Epoch 20, batch 36/72, loss: 0.2514\n",
      "Epoch 20, batch 41/72, loss: 0.2250\n",
      "Epoch 20, batch 46/72, loss: 0.2829\n",
      "Epoch 20, batch 51/72, loss: 0.1700\n",
      "Epoch 20, batch 56/72, loss: 0.1764\n",
      "Epoch 20, batch 61/72, loss: 0.1935\n",
      "Epoch 20, batch 66/72, loss: 0.1122\n",
      "Epoch 20, batch 71/72, loss: 0.2068\n",
      "Epoch 20, train loss: 0.2213, train accuracy: 93.11%\n",
      "Epoch 20, val loss: 0.3901, val accuracy: 86.89%\n",
      "Epoch 21, batch 1/72, loss: 0.1791\n",
      "Epoch 21, batch 6/72, loss: 0.2867\n",
      "Epoch 21, batch 11/72, loss: 0.1510\n",
      "Epoch 21, batch 16/72, loss: 0.1687\n",
      "Epoch 21, batch 21/72, loss: 0.1670\n",
      "Epoch 21, batch 26/72, loss: 0.1812\n",
      "Epoch 21, batch 31/72, loss: 0.2164\n",
      "Epoch 21, batch 36/72, loss: 0.1867\n",
      "Epoch 21, batch 41/72, loss: 0.2508\n",
      "Epoch 21, batch 46/72, loss: 0.1811\n",
      "Epoch 21, batch 51/72, loss: 0.1407\n",
      "Epoch 21, batch 56/72, loss: 0.1594\n",
      "Epoch 21, batch 61/72, loss: 0.1835\n",
      "Epoch 21, batch 66/72, loss: 0.2042\n",
      "Epoch 21, batch 71/72, loss: 0.2415\n",
      "Epoch 21, train loss: 0.1901, train accuracy: 94.45%\n",
      "Epoch 21, val loss: 0.3953, val accuracy: 86.81%\n",
      "Epoch 22, batch 1/72, loss: 0.1692\n",
      "Epoch 22, batch 6/72, loss: 0.1914\n",
      "Epoch 22, batch 11/72, loss: 0.1638\n",
      "Epoch 22, batch 16/72, loss: 0.1846\n",
      "Epoch 22, batch 21/72, loss: 0.1196\n",
      "Epoch 22, batch 26/72, loss: 0.1966\n",
      "Epoch 22, batch 31/72, loss: 0.1662\n",
      "Epoch 22, batch 36/72, loss: 0.2104\n",
      "Epoch 22, batch 41/72, loss: 0.0915\n",
      "Epoch 22, batch 46/72, loss: 0.1854\n",
      "Epoch 22, batch 51/72, loss: 0.1879\n",
      "Epoch 22, batch 56/72, loss: 0.0849\n",
      "Epoch 22, batch 61/72, loss: 0.1916\n",
      "Epoch 22, batch 66/72, loss: 0.1905\n",
      "Epoch 22, batch 71/72, loss: 0.2048\n",
      "Epoch 22, train loss: 0.1883, train accuracy: 94.09%\n",
      "Epoch 22, val loss: 0.4029, val accuracy: 86.76%\n",
      "Epoch 23, batch 1/72, loss: 0.2108\n",
      "Epoch 23, batch 6/72, loss: 0.1396\n",
      "Epoch 23, batch 11/72, loss: 0.2361\n",
      "Epoch 23, batch 16/72, loss: 0.1602\n",
      "Epoch 23, batch 21/72, loss: 0.1847\n",
      "Epoch 23, batch 26/72, loss: 0.1105\n",
      "Epoch 23, batch 31/72, loss: 0.1692\n",
      "Epoch 23, batch 36/72, loss: 0.1321\n",
      "Epoch 23, batch 41/72, loss: 0.1445\n",
      "Epoch 23, batch 46/72, loss: 0.1911\n",
      "Epoch 23, batch 51/72, loss: 0.2047\n",
      "Epoch 23, batch 56/72, loss: 0.1645\n",
      "Epoch 23, batch 61/72, loss: 0.2504\n",
      "Epoch 23, batch 66/72, loss: 0.1694\n",
      "Epoch 23, batch 71/72, loss: 0.2185\n",
      "Epoch 23, train loss: 0.1876, train accuracy: 93.91%\n",
      "Epoch 23, val loss: 0.4422, val accuracy: 85.37%\n",
      "Epoch 24, batch 1/72, loss: 0.2223\n",
      "Epoch 24, batch 6/72, loss: 0.2542\n",
      "Epoch 24, batch 11/72, loss: 0.1320\n",
      "Epoch 24, batch 16/72, loss: 0.1662\n",
      "Epoch 24, batch 21/72, loss: 0.1486\n",
      "Epoch 24, batch 26/72, loss: 0.1749\n",
      "Epoch 24, batch 31/72, loss: 0.1554\n",
      "Epoch 24, batch 36/72, loss: 0.1621\n",
      "Epoch 24, batch 41/72, loss: 0.2755\n",
      "Epoch 24, batch 46/72, loss: 0.1753\n",
      "Epoch 24, batch 51/72, loss: 0.2189\n",
      "Epoch 24, batch 56/72, loss: 0.1224\n",
      "Epoch 24, batch 61/72, loss: 0.2415\n",
      "Epoch 24, batch 66/72, loss: 0.2518\n",
      "Epoch 24, batch 71/72, loss: 0.3182\n",
      "Epoch 24, train loss: 0.1872, train accuracy: 94.09%\n",
      "Epoch 24, val loss: 0.4212, val accuracy: 85.85%\n",
      "Epoch 25, batch 1/72, loss: 0.1560\n",
      "Epoch 25, batch 6/72, loss: 0.1661\n",
      "Epoch 25, batch 11/72, loss: 0.1098\n",
      "Epoch 25, batch 16/72, loss: 0.2999\n",
      "Epoch 25, batch 21/72, loss: 0.1663\n",
      "Epoch 25, batch 26/72, loss: 0.2840\n",
      "Epoch 25, batch 31/72, loss: 0.1947\n",
      "Epoch 25, batch 36/72, loss: 0.1119\n",
      "Epoch 25, batch 41/72, loss: 0.1642\n",
      "Epoch 25, batch 46/72, loss: 0.1570\n",
      "Epoch 25, batch 51/72, loss: 0.1034\n",
      "Epoch 25, batch 56/72, loss: 0.2278\n",
      "Epoch 25, batch 61/72, loss: 0.1191\n",
      "Epoch 25, batch 66/72, loss: 0.1708\n",
      "Epoch 25, batch 71/72, loss: 0.1849\n",
      "Epoch 25, train loss: 0.1676, train accuracy: 94.64%\n",
      "Epoch 25, val loss: 0.4143, val accuracy: 86.89%\n",
      "Epoch 26, batch 1/72, loss: 0.1420\n",
      "Epoch 26, batch 6/72, loss: 0.1256\n",
      "Epoch 26, batch 11/72, loss: 0.1890\n",
      "Epoch 26, batch 16/72, loss: 0.1725\n",
      "Epoch 26, batch 21/72, loss: 0.1861\n",
      "Epoch 26, batch 26/72, loss: 0.1638\n",
      "Epoch 26, batch 31/72, loss: 0.1502\n",
      "Epoch 26, batch 36/72, loss: 0.1451\n",
      "Epoch 26, batch 41/72, loss: 0.1963\n",
      "Epoch 26, batch 46/72, loss: 0.1642\n",
      "Epoch 26, batch 51/72, loss: 0.1013\n",
      "Epoch 26, batch 56/72, loss: 0.0938\n",
      "Epoch 26, batch 61/72, loss: 0.2073\n",
      "Epoch 26, batch 66/72, loss: 0.1718\n",
      "Epoch 26, batch 71/72, loss: 0.1924\n",
      "Epoch 26, train loss: 0.1478, train accuracy: 95.53%\n",
      "Epoch 26, val loss: 0.3814, val accuracy: 87.41%\n",
      "Epoch 27, batch 1/72, loss: 0.1191\n",
      "Epoch 27, batch 6/72, loss: 0.0912\n",
      "Epoch 27, batch 11/72, loss: 0.1511\n",
      "Epoch 27, batch 16/72, loss: 0.1383\n",
      "Epoch 27, batch 21/72, loss: 0.1311\n",
      "Epoch 27, batch 26/72, loss: 0.1400\n",
      "Epoch 27, batch 31/72, loss: 0.1937\n",
      "Epoch 27, batch 36/72, loss: 0.1147\n",
      "Epoch 27, batch 41/72, loss: 0.1067\n",
      "Epoch 27, batch 46/72, loss: 0.1581\n",
      "Epoch 27, batch 51/72, loss: 0.1686\n",
      "Epoch 27, batch 56/72, loss: 0.1949\n",
      "Epoch 27, batch 61/72, loss: 0.1887\n",
      "Epoch 27, batch 66/72, loss: 0.1920\n",
      "Epoch 27, batch 71/72, loss: 0.1941\n",
      "Epoch 27, train loss: 0.1442, train accuracy: 95.52%\n",
      "Epoch 27, val loss: 0.4362, val accuracy: 85.68%\n",
      "Epoch 28, batch 1/72, loss: 0.2446\n",
      "Epoch 28, batch 6/72, loss: 0.1514\n",
      "Epoch 28, batch 11/72, loss: 0.1631\n",
      "Epoch 28, batch 16/72, loss: 0.0963\n",
      "Epoch 28, batch 21/72, loss: 0.1552\n",
      "Epoch 28, batch 26/72, loss: 0.0884\n",
      "Epoch 28, batch 31/72, loss: 0.1597\n",
      "Epoch 28, batch 36/72, loss: 0.1386\n",
      "Epoch 28, batch 41/72, loss: 0.1657\n",
      "Epoch 28, batch 46/72, loss: 0.1322\n",
      "Epoch 28, batch 51/72, loss: 0.1499\n",
      "Epoch 28, batch 56/72, loss: 0.1401\n",
      "Epoch 28, batch 61/72, loss: 0.0939\n",
      "Epoch 28, batch 66/72, loss: 0.1986\n",
      "Epoch 28, batch 71/72, loss: 0.1334\n",
      "Epoch 28, train loss: 0.1416, train accuracy: 95.56%\n",
      "Epoch 28, val loss: 0.3769, val accuracy: 87.63%\n",
      "Epoch 29, batch 1/72, loss: 0.1318\n",
      "Epoch 29, batch 6/72, loss: 0.1020\n",
      "Epoch 29, batch 11/72, loss: 0.1298\n",
      "Epoch 29, batch 16/72, loss: 0.1321\n",
      "Epoch 29, batch 21/72, loss: 0.1143\n",
      "Epoch 29, batch 26/72, loss: 0.0856\n",
      "Epoch 29, batch 31/72, loss: 0.0653\n",
      "Epoch 29, batch 36/72, loss: 0.0737\n",
      "Epoch 29, batch 41/72, loss: 0.1266\n",
      "Epoch 29, batch 46/72, loss: 0.1410\n",
      "Epoch 29, batch 51/72, loss: 0.1267\n",
      "Epoch 29, batch 56/72, loss: 0.1147\n",
      "Epoch 29, batch 61/72, loss: 0.1353\n",
      "Epoch 29, batch 66/72, loss: 0.1690\n",
      "Epoch 29, batch 71/72, loss: 0.0992\n",
      "Epoch 29, train loss: 0.1218, train accuracy: 96.40%\n",
      "Epoch 29, val loss: 0.3960, val accuracy: 87.46%\n",
      "Epoch 30, batch 1/72, loss: 0.0662\n",
      "Epoch 30, batch 6/72, loss: 0.0857\n",
      "Epoch 30, batch 11/72, loss: 0.1253\n",
      "Epoch 30, batch 16/72, loss: 0.0891\n",
      "Epoch 30, batch 21/72, loss: 0.1319\n",
      "Epoch 30, batch 26/72, loss: 0.1078\n",
      "Epoch 30, batch 31/72, loss: 0.0945\n",
      "Epoch 30, batch 36/72, loss: 0.0790\n",
      "Epoch 30, batch 41/72, loss: 0.0526\n",
      "Epoch 30, batch 46/72, loss: 0.2196\n",
      "Epoch 30, batch 51/72, loss: 0.1353\n",
      "Epoch 30, batch 56/72, loss: 0.1137\n",
      "Epoch 30, batch 61/72, loss: 0.1645\n",
      "Epoch 30, batch 66/72, loss: 0.1129\n",
      "Epoch 30, batch 71/72, loss: 0.1422\n",
      "Epoch 30, train loss: 0.1301, train accuracy: 96.08%\n",
      "Epoch 30, val loss: 0.3713, val accuracy: 88.28%\n",
      "Epoch 31, batch 1/72, loss: 0.0802\n",
      "Epoch 31, batch 6/72, loss: 0.1047\n",
      "Epoch 31, batch 11/72, loss: 0.0543\n",
      "Epoch 31, batch 16/72, loss: 0.1674\n",
      "Epoch 31, batch 21/72, loss: 0.1146\n",
      "Epoch 31, batch 26/72, loss: 0.1294\n",
      "Epoch 31, batch 31/72, loss: 0.1000\n",
      "Epoch 31, batch 36/72, loss: 0.1431\n",
      "Epoch 31, batch 41/72, loss: 0.0931\n",
      "Epoch 31, batch 46/72, loss: 0.1099\n",
      "Epoch 31, batch 51/72, loss: 0.1301\n",
      "Epoch 31, batch 56/72, loss: 0.0859\n",
      "Epoch 31, batch 61/72, loss: 0.1454\n",
      "Epoch 31, batch 66/72, loss: 0.0986\n",
      "Epoch 31, batch 71/72, loss: 0.1515\n",
      "Epoch 31, train loss: 0.1108, train accuracy: 97.03%\n",
      "Epoch 31, val loss: 0.3868, val accuracy: 87.89%\n",
      "Epoch 32, batch 1/72, loss: 0.0818\n",
      "Epoch 32, batch 6/72, loss: 0.1336\n",
      "Epoch 32, batch 11/72, loss: 0.1605\n",
      "Epoch 32, batch 16/72, loss: 0.0780\n",
      "Epoch 32, batch 21/72, loss: 0.0378\n",
      "Epoch 32, batch 26/72, loss: 0.0803\n",
      "Epoch 32, batch 31/72, loss: 0.0933\n",
      "Epoch 32, batch 36/72, loss: 0.1130\n",
      "Epoch 32, batch 41/72, loss: 0.0708\n",
      "Epoch 32, batch 46/72, loss: 0.0848\n",
      "Epoch 32, batch 51/72, loss: 0.0754\n",
      "Epoch 32, batch 56/72, loss: 0.1053\n",
      "Epoch 32, batch 61/72, loss: 0.0894\n",
      "Epoch 32, batch 66/72, loss: 0.1235\n",
      "Epoch 32, batch 71/72, loss: 0.0336\n",
      "Epoch 32, train loss: 0.1030, train accuracy: 97.05%\n",
      "Epoch 32, val loss: 0.3771, val accuracy: 88.24%\n",
      "Epoch 33, batch 1/72, loss: 0.0858\n",
      "Epoch 33, batch 6/72, loss: 0.1293\n",
      "Epoch 33, batch 11/72, loss: 0.1366\n",
      "Epoch 33, batch 16/72, loss: 0.0841\n",
      "Epoch 33, batch 21/72, loss: 0.0923\n",
      "Epoch 33, batch 26/72, loss: 0.0725\n",
      "Epoch 33, batch 31/72, loss: 0.0903\n",
      "Epoch 33, batch 36/72, loss: 0.1304\n",
      "Epoch 33, batch 41/72, loss: 0.1251\n",
      "Epoch 33, batch 46/72, loss: 0.0932\n",
      "Epoch 33, batch 51/72, loss: 0.0577\n",
      "Epoch 33, batch 56/72, loss: 0.0884\n",
      "Epoch 33, batch 61/72, loss: 0.0825\n",
      "Epoch 33, batch 66/72, loss: 0.0808\n",
      "Epoch 33, batch 71/72, loss: 0.0687\n",
      "Epoch 33, train loss: 0.0969, train accuracy: 97.32%\n",
      "Epoch 33, val loss: 0.3718, val accuracy: 88.19%\n",
      "Epoch 34, batch 1/72, loss: 0.0625\n",
      "Epoch 34, batch 6/72, loss: 0.0778\n",
      "Epoch 34, batch 11/72, loss: 0.0510\n",
      "Epoch 34, batch 16/72, loss: 0.0650\n",
      "Epoch 34, batch 21/72, loss: 0.0987\n",
      "Epoch 34, batch 26/72, loss: 0.0574\n",
      "Epoch 34, batch 31/72, loss: 0.0589\n",
      "Epoch 34, batch 36/72, loss: 0.1061\n",
      "Epoch 34, batch 41/72, loss: 0.0707\n",
      "Epoch 34, batch 46/72, loss: 0.1641\n",
      "Epoch 34, batch 51/72, loss: 0.0693\n",
      "Epoch 34, batch 56/72, loss: 0.0744\n",
      "Epoch 34, batch 61/72, loss: 0.1823\n",
      "Epoch 34, batch 66/72, loss: 0.1070\n",
      "Epoch 34, batch 71/72, loss: 0.1025\n",
      "Epoch 34, train loss: 0.0842, train accuracy: 97.78%\n",
      "Epoch 34, val loss: 0.3945, val accuracy: 87.41%\n",
      "Epoch 35, batch 1/72, loss: 0.0685\n",
      "Epoch 35, batch 6/72, loss: 0.0928\n",
      "Epoch 35, batch 11/72, loss: 0.0507\n",
      "Epoch 35, batch 16/72, loss: 0.0494\n",
      "Epoch 35, batch 21/72, loss: 0.0868\n",
      "Epoch 35, batch 26/72, loss: 0.1353\n",
      "Epoch 35, batch 31/72, loss: 0.1045\n",
      "Epoch 35, batch 36/72, loss: 0.0762\n",
      "Epoch 35, batch 41/72, loss: 0.1049\n",
      "Epoch 35, batch 46/72, loss: 0.1780\n",
      "Epoch 35, batch 51/72, loss: 0.0505\n",
      "Epoch 35, batch 56/72, loss: 0.1230\n",
      "Epoch 35, batch 61/72, loss: 0.0773\n",
      "Epoch 35, batch 66/72, loss: 0.0636\n",
      "Epoch 35, batch 71/72, loss: 0.0736\n",
      "Epoch 35, train loss: 0.0851, train accuracy: 97.65%\n",
      "Epoch 35, val loss: 0.3735, val accuracy: 88.24%\n",
      "Epoch 36, batch 1/72, loss: 0.0396\n",
      "Epoch 36, batch 6/72, loss: 0.0977\n",
      "Epoch 36, batch 11/72, loss: 0.0571\n",
      "Epoch 36, batch 16/72, loss: 0.0697\n",
      "Epoch 36, batch 21/72, loss: 0.0780\n",
      "Epoch 36, batch 26/72, loss: 0.0913\n",
      "Epoch 36, batch 31/72, loss: 0.1200\n",
      "Epoch 36, batch 36/72, loss: 0.0738\n",
      "Epoch 36, batch 41/72, loss: 0.0745\n",
      "Epoch 36, batch 46/72, loss: 0.1582\n",
      "Epoch 36, batch 51/72, loss: 0.0575\n",
      "Epoch 36, batch 56/72, loss: 0.0907\n",
      "Epoch 36, batch 61/72, loss: 0.0549\n",
      "Epoch 36, batch 66/72, loss: 0.0754\n",
      "Epoch 36, batch 71/72, loss: 0.0904\n",
      "Epoch 36, train loss: 0.0810, train accuracy: 97.81%\n",
      "Epoch 36, val loss: 0.3694, val accuracy: 88.06%\n",
      "Epoch 37, batch 1/72, loss: 0.1375\n",
      "Epoch 37, batch 6/72, loss: 0.0714\n",
      "Epoch 37, batch 11/72, loss: 0.0377\n",
      "Epoch 37, batch 16/72, loss: 0.0717\n",
      "Epoch 37, batch 21/72, loss: 0.0691\n",
      "Epoch 37, batch 26/72, loss: 0.1295\n",
      "Epoch 37, batch 31/72, loss: 0.0501\n",
      "Epoch 37, batch 36/72, loss: 0.0723\n",
      "Epoch 37, batch 41/72, loss: 0.0670\n",
      "Epoch 37, batch 46/72, loss: 0.0549\n",
      "Epoch 37, batch 51/72, loss: 0.0951\n",
      "Epoch 37, batch 56/72, loss: 0.0777\n",
      "Epoch 37, batch 61/72, loss: 0.0740\n",
      "Epoch 37, batch 66/72, loss: 0.0611\n",
      "Epoch 37, batch 71/72, loss: 0.0544\n",
      "Epoch 37, train loss: 0.0671, train accuracy: 98.45%\n",
      "Epoch 37, val loss: 0.3522, val accuracy: 88.59%\n",
      "Epoch 38, batch 1/72, loss: 0.0590\n",
      "Epoch 38, batch 6/72, loss: 0.0718\n",
      "Epoch 38, batch 11/72, loss: 0.0537\n",
      "Epoch 38, batch 16/72, loss: 0.0433\n",
      "Epoch 38, batch 21/72, loss: 0.0394\n",
      "Epoch 38, batch 26/72, loss: 0.1799\n",
      "Epoch 38, batch 31/72, loss: 0.0654\n",
      "Epoch 38, batch 36/72, loss: 0.0844\n",
      "Epoch 38, batch 41/72, loss: 0.0763\n",
      "Epoch 38, batch 46/72, loss: 0.0757\n",
      "Epoch 38, batch 51/72, loss: 0.0711\n",
      "Epoch 38, batch 56/72, loss: 0.0449\n",
      "Epoch 38, batch 61/72, loss: 0.0409\n",
      "Epoch 38, batch 66/72, loss: 0.1304\n",
      "Epoch 38, batch 71/72, loss: 0.0563\n",
      "Epoch 38, train loss: 0.0659, train accuracy: 98.38%\n",
      "Epoch 38, val loss: 0.3662, val accuracy: 88.85%\n",
      "Epoch 39, batch 1/72, loss: 0.1080\n",
      "Epoch 39, batch 6/72, loss: 0.0264\n",
      "Epoch 39, batch 11/72, loss: 0.0497\n",
      "Epoch 39, batch 16/72, loss: 0.0533\n",
      "Epoch 39, batch 21/72, loss: 0.0645\n",
      "Epoch 39, batch 26/72, loss: 0.0458\n",
      "Epoch 39, batch 31/72, loss: 0.0644\n",
      "Epoch 39, batch 36/72, loss: 0.0413\n",
      "Epoch 39, batch 41/72, loss: 0.0698\n",
      "Epoch 39, batch 46/72, loss: 0.1108\n",
      "Epoch 39, batch 51/72, loss: 0.0396\n",
      "Epoch 39, batch 56/72, loss: 0.0401\n",
      "Epoch 39, batch 61/72, loss: 0.0599\n",
      "Epoch 39, batch 66/72, loss: 0.0615\n",
      "Epoch 39, batch 71/72, loss: 0.0612\n",
      "Epoch 39, train loss: 0.0637, train accuracy: 98.38%\n",
      "Epoch 39, val loss: 0.3575, val accuracy: 88.93%\n",
      "Epoch 40, batch 1/72, loss: 0.1070\n",
      "Epoch 40, batch 6/72, loss: 0.1607\n",
      "Epoch 40, batch 11/72, loss: 0.0423\n",
      "Epoch 40, batch 16/72, loss: 0.0905\n",
      "Epoch 40, batch 21/72, loss: 0.0641\n",
      "Epoch 40, batch 26/72, loss: 0.0887\n",
      "Epoch 40, batch 31/72, loss: 0.0464\n",
      "Epoch 40, batch 36/72, loss: 0.1248\n",
      "Epoch 40, batch 41/72, loss: 0.0717\n",
      "Epoch 40, batch 46/72, loss: 0.0631\n",
      "Epoch 40, batch 51/72, loss: 0.0538\n",
      "Epoch 40, batch 56/72, loss: 0.0596\n",
      "Epoch 40, batch 61/72, loss: 0.0559\n",
      "Epoch 40, batch 66/72, loss: 0.0522\n",
      "Epoch 40, batch 71/72, loss: 0.0242\n",
      "Epoch 40, train loss: 0.0608, train accuracy: 98.68%\n",
      "Epoch 40, val loss: 0.3585, val accuracy: 89.24%\n",
      "Epoch 41, batch 1/72, loss: 0.0384\n",
      "Epoch 41, batch 6/72, loss: 0.0328\n",
      "Epoch 41, batch 11/72, loss: 0.0476\n",
      "Epoch 41, batch 16/72, loss: 0.0272\n",
      "Epoch 41, batch 21/72, loss: 0.0429\n",
      "Epoch 41, batch 26/72, loss: 0.0535\n",
      "Epoch 41, batch 31/72, loss: 0.0792\n",
      "Epoch 41, batch 36/72, loss: 0.1068\n",
      "Epoch 41, batch 41/72, loss: 0.0445\n",
      "Epoch 41, batch 46/72, loss: 0.0779\n",
      "Epoch 41, batch 51/72, loss: 0.0433\n",
      "Epoch 41, batch 56/72, loss: 0.0516\n",
      "Epoch 41, batch 61/72, loss: 0.0325\n",
      "Epoch 41, batch 66/72, loss: 0.0620\n",
      "Epoch 41, batch 71/72, loss: 0.1047\n",
      "Epoch 41, train loss: 0.0542, train accuracy: 98.72%\n",
      "Epoch 41, val loss: 0.3670, val accuracy: 88.63%\n",
      "Epoch 42, batch 1/72, loss: 0.0388\n",
      "Epoch 42, batch 6/72, loss: 0.0384\n",
      "Epoch 42, batch 11/72, loss: 0.0756\n",
      "Epoch 42, batch 16/72, loss: 0.0316\n",
      "Epoch 42, batch 21/72, loss: 0.0956\n",
      "Epoch 42, batch 26/72, loss: 0.1077\n",
      "Epoch 42, batch 31/72, loss: 0.1472\n",
      "Epoch 42, batch 36/72, loss: 0.1215\n",
      "Epoch 42, batch 41/72, loss: 0.0263\n",
      "Epoch 42, batch 46/72, loss: 0.0802\n",
      "Epoch 42, batch 51/72, loss: 0.0523\n",
      "Epoch 42, batch 56/72, loss: 0.0746\n",
      "Epoch 42, batch 61/72, loss: 0.0627\n",
      "Epoch 42, batch 66/72, loss: 0.0645\n",
      "Epoch 42, batch 71/72, loss: 0.0440\n",
      "Epoch 42, train loss: 0.0716, train accuracy: 98.04%\n",
      "Epoch 42, val loss: 0.3681, val accuracy: 88.28%\n",
      "Epoch 43, batch 1/72, loss: 0.0476\n",
      "Epoch 43, batch 6/72, loss: 0.0514\n",
      "Epoch 43, batch 11/72, loss: 0.0516\n",
      "Epoch 43, batch 16/72, loss: 0.0661\n",
      "Epoch 43, batch 21/72, loss: 0.0288\n",
      "Epoch 43, batch 26/72, loss: 0.0611\n",
      "Epoch 43, batch 31/72, loss: 0.0558\n",
      "Epoch 43, batch 36/72, loss: 0.0438\n",
      "Epoch 43, batch 41/72, loss: 0.0266\n",
      "Epoch 43, batch 46/72, loss: 0.0562\n",
      "Epoch 43, batch 51/72, loss: 0.0265\n",
      "Epoch 43, batch 56/72, loss: 0.0413\n",
      "Epoch 43, batch 61/72, loss: 0.0477\n",
      "Epoch 43, batch 66/72, loss: 0.0282\n",
      "Epoch 43, batch 71/72, loss: 0.0933\n",
      "Epoch 43, train loss: 0.0535, train accuracy: 98.80%\n",
      "Epoch 43, val loss: 0.3644, val accuracy: 89.28%\n",
      "Epoch 44, batch 1/72, loss: 0.0282\n",
      "Epoch 44, batch 6/72, loss: 0.0381\n",
      "Epoch 44, batch 11/72, loss: 0.0426\n",
      "Epoch 44, batch 16/72, loss: 0.0452\n",
      "Epoch 44, batch 21/72, loss: 0.0845\n",
      "Epoch 44, batch 26/72, loss: 0.0405\n",
      "Epoch 44, batch 31/72, loss: 0.0519\n",
      "Epoch 44, batch 36/72, loss: 0.0350\n",
      "Epoch 44, batch 41/72, loss: 0.0363\n",
      "Epoch 44, batch 46/72, loss: 0.0290\n",
      "Epoch 44, batch 51/72, loss: 0.0334\n",
      "Epoch 44, batch 56/72, loss: 0.0311\n",
      "Epoch 44, batch 61/72, loss: 0.0486\n",
      "Epoch 44, batch 66/72, loss: 0.0399\n",
      "Epoch 44, batch 71/72, loss: 0.0782\n",
      "Epoch 44, train loss: 0.0472, train accuracy: 99.03%\n",
      "Epoch 44, val loss: 0.3727, val accuracy: 89.06%\n",
      "Epoch 45, batch 1/72, loss: 0.0444\n",
      "Epoch 45, batch 6/72, loss: 0.0281\n",
      "Epoch 45, batch 11/72, loss: 0.0407\n",
      "Epoch 45, batch 16/72, loss: 0.0270\n",
      "Epoch 45, batch 21/72, loss: 0.0412\n",
      "Epoch 45, batch 26/72, loss: 0.0434\n",
      "Epoch 45, batch 31/72, loss: 0.0213\n",
      "Epoch 45, batch 36/72, loss: 0.0405\n",
      "Epoch 45, batch 41/72, loss: 0.0444\n",
      "Epoch 45, batch 46/72, loss: 0.1049\n",
      "Epoch 45, batch 51/72, loss: 0.0639\n",
      "Epoch 45, batch 56/72, loss: 0.0697\n",
      "Epoch 45, batch 61/72, loss: 0.1309\n",
      "Epoch 45, batch 66/72, loss: 0.0925\n",
      "Epoch 45, batch 71/72, loss: 0.0508\n",
      "Epoch 45, train loss: 0.0542, train accuracy: 98.76%\n",
      "Epoch 45, val loss: 0.3690, val accuracy: 88.41%\n",
      "Epoch 46, batch 1/72, loss: 0.0324\n",
      "Epoch 46, batch 6/72, loss: 0.0695\n",
      "Epoch 46, batch 11/72, loss: 0.0653\n",
      "Epoch 46, batch 16/72, loss: 0.0409\n",
      "Epoch 46, batch 21/72, loss: 0.0325\n",
      "Epoch 46, batch 26/72, loss: 0.0624\n",
      "Epoch 46, batch 31/72, loss: 0.0389\n",
      "Epoch 46, batch 36/72, loss: 0.0246\n",
      "Epoch 46, batch 41/72, loss: 0.0431\n",
      "Epoch 46, batch 46/72, loss: 0.0671\n",
      "Epoch 46, batch 51/72, loss: 0.0699\n",
      "Epoch 46, batch 56/72, loss: 0.0911\n",
      "Epoch 46, batch 61/72, loss: 0.0963\n",
      "Epoch 46, batch 66/72, loss: 0.0668\n",
      "Epoch 46, batch 71/72, loss: 0.0654\n",
      "Epoch 46, train loss: 0.0623, train accuracy: 98.30%\n",
      "Epoch 46, val loss: 0.3737, val accuracy: 88.50%\n",
      "Epoch 47, batch 1/72, loss: 0.0694\n",
      "Epoch 47, batch 6/72, loss: 0.0464\n",
      "Epoch 47, batch 11/72, loss: 0.0529\n",
      "Epoch 47, batch 16/72, loss: 0.0471\n",
      "Epoch 47, batch 21/72, loss: 0.0321\n",
      "Epoch 47, batch 26/72, loss: 0.0383\n",
      "Epoch 47, batch 31/72, loss: 0.0490\n",
      "Epoch 47, batch 36/72, loss: 0.0248\n",
      "Epoch 47, batch 41/72, loss: 0.0407\n",
      "Epoch 47, batch 46/72, loss: 0.0305\n",
      "Epoch 47, batch 51/72, loss: 0.0464\n",
      "Epoch 47, batch 56/72, loss: 0.0238\n",
      "Epoch 47, batch 61/72, loss: 0.0377\n",
      "Epoch 47, batch 66/72, loss: 0.0382\n",
      "Epoch 47, batch 71/72, loss: 0.0680\n",
      "Epoch 47, train loss: 0.0482, train accuracy: 98.87%\n",
      "Epoch 47, val loss: 0.3743, val accuracy: 88.67%\n",
      "Epoch 48, batch 1/72, loss: 0.0173\n",
      "Epoch 48, batch 6/72, loss: 0.0504\n",
      "Epoch 48, batch 11/72, loss: 0.0441\n",
      "Epoch 48, batch 16/72, loss: 0.0372\n",
      "Epoch 48, batch 21/72, loss: 0.0299\n",
      "Epoch 48, batch 26/72, loss: 0.0536\n",
      "Epoch 48, batch 31/72, loss: 0.0698\n",
      "Epoch 48, batch 36/72, loss: 0.0584\n",
      "Epoch 48, batch 41/72, loss: 0.0341\n",
      "Epoch 48, batch 46/72, loss: 0.0475\n",
      "Epoch 48, batch 51/72, loss: 0.0225\n",
      "Epoch 48, batch 56/72, loss: 0.0445\n",
      "Epoch 48, batch 61/72, loss: 0.0311\n",
      "Epoch 48, batch 66/72, loss: 0.0453\n",
      "Epoch 48, batch 71/72, loss: 0.0355\n",
      "Epoch 48, train loss: 0.0423, train accuracy: 99.23%\n",
      "Epoch 48, val loss: 0.3695, val accuracy: 88.41%\n",
      "Epoch 49, batch 1/72, loss: 0.0683\n",
      "Epoch 49, batch 6/72, loss: 0.0215\n",
      "Epoch 49, batch 11/72, loss: 0.0176\n",
      "Epoch 49, batch 16/72, loss: 0.0308\n",
      "Epoch 49, batch 21/72, loss: 0.0247\n",
      "Epoch 49, batch 26/72, loss: 0.0322\n",
      "Epoch 49, batch 31/72, loss: 0.0375\n",
      "Epoch 49, batch 36/72, loss: 0.0327\n",
      "Epoch 49, batch 41/72, loss: 0.0521\n",
      "Epoch 49, batch 46/72, loss: 0.0583\n",
      "Epoch 49, batch 51/72, loss: 0.0399\n",
      "Epoch 49, batch 56/72, loss: 0.0439\n",
      "Epoch 49, batch 61/72, loss: 0.0453\n",
      "Epoch 49, batch 66/72, loss: 0.0432\n",
      "Epoch 49, batch 71/72, loss: 0.0390\n",
      "Epoch 49, train loss: 0.0435, train accuracy: 98.99%\n",
      "Epoch 49, val loss: 0.3826, val accuracy: 88.54%\n",
      "Epoch 50, batch 1/72, loss: 0.0325\n",
      "Epoch 50, batch 6/72, loss: 0.0368\n",
      "Epoch 50, batch 11/72, loss: 0.0322\n",
      "Epoch 50, batch 16/72, loss: 0.0132\n",
      "Epoch 50, batch 21/72, loss: 0.0269\n",
      "Epoch 50, batch 26/72, loss: 0.0714\n",
      "Epoch 50, batch 31/72, loss: 0.0290\n",
      "Epoch 50, batch 36/72, loss: 0.0204\n",
      "Epoch 50, batch 41/72, loss: 0.0176\n",
      "Epoch 50, batch 46/72, loss: 0.0231\n",
      "Epoch 50, batch 51/72, loss: 0.0261\n",
      "Epoch 50, batch 56/72, loss: 0.0272\n",
      "Epoch 50, batch 61/72, loss: 0.0211\n",
      "Epoch 50, batch 66/72, loss: 0.0383\n",
      "Epoch 50, batch 71/72, loss: 0.0511\n",
      "Epoch 50, train loss: 0.0358, train accuracy: 99.33%\n",
      "Epoch 50, val loss: 0.3870, val accuracy: 88.19%\n",
      "Epoch 51, batch 1/72, loss: 0.0362\n",
      "Epoch 51, batch 6/72, loss: 0.0352\n",
      "Epoch 51, batch 11/72, loss: 0.0476\n",
      "Epoch 51, batch 16/72, loss: 0.0168\n",
      "Epoch 51, batch 21/72, loss: 0.0143\n",
      "Epoch 51, batch 26/72, loss: 0.0356\n",
      "Epoch 51, batch 31/72, loss: 0.0165\n",
      "Epoch 51, batch 36/72, loss: 0.0223\n",
      "Epoch 51, batch 41/72, loss: 0.0607\n",
      "Epoch 51, batch 46/72, loss: 0.0207\n",
      "Epoch 51, batch 51/72, loss: 0.0466\n",
      "Epoch 51, batch 56/72, loss: 0.0196\n",
      "Epoch 51, batch 61/72, loss: 0.0273\n",
      "Epoch 51, batch 66/72, loss: 0.0187\n",
      "Epoch 51, batch 71/72, loss: 0.0217\n",
      "Epoch 51, train loss: 0.0394, train accuracy: 98.97%\n",
      "Epoch 51, val loss: 0.3818, val accuracy: 88.45%\n",
      "Epoch 52, batch 1/72, loss: 0.0926\n",
      "Epoch 52, batch 6/72, loss: 0.0206\n",
      "Epoch 52, batch 11/72, loss: 0.0218\n",
      "Epoch 52, batch 16/72, loss: 0.0384\n",
      "Epoch 52, batch 21/72, loss: 0.0213\n",
      "Epoch 52, batch 26/72, loss: 0.0208\n",
      "Epoch 52, batch 31/72, loss: 0.0586\n",
      "Epoch 52, batch 36/72, loss: 0.0231\n",
      "Epoch 52, batch 41/72, loss: 0.0544\n",
      "Epoch 52, batch 46/72, loss: 0.0163\n",
      "Epoch 52, batch 51/72, loss: 0.0221\n",
      "Epoch 52, batch 56/72, loss: 0.0297\n",
      "Epoch 52, batch 61/72, loss: 0.0330\n",
      "Epoch 52, batch 66/72, loss: 0.0098\n",
      "Epoch 52, batch 71/72, loss: 0.0208\n",
      "Epoch 52, train loss: 0.0342, train accuracy: 99.22%\n",
      "Epoch 52, val loss: 0.3845, val accuracy: 88.63%\n",
      "Epoch 53, batch 1/72, loss: 0.0255\n",
      "Epoch 53, batch 6/72, loss: 0.0174\n",
      "Epoch 53, batch 11/72, loss: 0.0740\n",
      "Epoch 53, batch 16/72, loss: 0.0321\n",
      "Epoch 53, batch 21/72, loss: 0.0281\n",
      "Epoch 53, batch 26/72, loss: 0.0572\n",
      "Epoch 53, batch 31/72, loss: 0.0901\n",
      "Epoch 53, batch 36/72, loss: 0.0518\n",
      "Epoch 53, batch 41/72, loss: 0.0396\n",
      "Epoch 53, batch 46/72, loss: 0.0195\n",
      "Epoch 53, batch 51/72, loss: 0.0269\n",
      "Epoch 53, batch 56/72, loss: 0.0279\n",
      "Epoch 53, batch 61/72, loss: 0.0273\n",
      "Epoch 53, batch 66/72, loss: 0.0212\n",
      "Epoch 53, batch 71/72, loss: 0.0435\n",
      "Epoch 53, train loss: 0.0432, train accuracy: 98.82%\n",
      "Epoch 53, val loss: 0.3769, val accuracy: 89.02%\n",
      "Epoch 54, batch 1/72, loss: 0.0885\n",
      "Epoch 54, batch 6/72, loss: 0.0644\n",
      "Epoch 54, batch 11/72, loss: 0.0299\n",
      "Epoch 54, batch 16/72, loss: 0.0476\n",
      "Epoch 54, batch 21/72, loss: 0.0165\n",
      "Epoch 54, batch 26/72, loss: 0.0380\n",
      "Epoch 54, batch 31/72, loss: 0.0124\n",
      "Epoch 54, batch 36/72, loss: 0.0249\n",
      "Epoch 54, batch 41/72, loss: 0.0200\n",
      "Epoch 54, batch 46/72, loss: 0.0254\n",
      "Epoch 54, batch 51/72, loss: 0.0216\n",
      "Epoch 54, batch 56/72, loss: 0.0253\n",
      "Epoch 54, batch 61/72, loss: 0.0929\n",
      "Epoch 54, batch 66/72, loss: 0.0345\n",
      "Epoch 54, batch 71/72, loss: 0.0211\n",
      "Epoch 54, train loss: 0.0307, train accuracy: 99.38%\n",
      "Epoch 54, val loss: 0.4044, val accuracy: 88.32%\n",
      "Epoch 55, batch 1/72, loss: 0.0216\n",
      "Epoch 55, batch 6/72, loss: 0.0361\n",
      "Epoch 55, batch 11/72, loss: 0.0703\n",
      "Epoch 55, batch 16/72, loss: 0.0207\n",
      "Epoch 55, batch 21/72, loss: 0.0309\n",
      "Epoch 55, batch 26/72, loss: 0.0310\n",
      "Epoch 55, batch 31/72, loss: 0.0340\n",
      "Epoch 55, batch 36/72, loss: 0.0222\n",
      "Epoch 55, batch 41/72, loss: 0.0409\n",
      "Epoch 55, batch 46/72, loss: 0.0138\n",
      "Epoch 55, batch 51/72, loss: 0.0548\n",
      "Epoch 55, batch 56/72, loss: 0.0359\n",
      "Epoch 55, batch 61/72, loss: 0.0216\n",
      "Epoch 55, batch 66/72, loss: 0.0371\n",
      "Epoch 55, batch 71/72, loss: 0.0201\n",
      "Epoch 55, train loss: 0.0312, train accuracy: 99.42%\n",
      "Epoch 55, val loss: 0.3748, val accuracy: 88.85%\n",
      "Epoch 56, batch 1/72, loss: 0.0199\n",
      "Epoch 56, batch 6/72, loss: 0.0504\n",
      "Epoch 56, batch 11/72, loss: 0.0536\n",
      "Epoch 56, batch 16/72, loss: 0.0124\n",
      "Epoch 56, batch 21/72, loss: 0.0275\n",
      "Epoch 56, batch 26/72, loss: 0.0174\n",
      "Epoch 56, batch 31/72, loss: 0.0227\n",
      "Epoch 56, batch 36/72, loss: 0.0635\n",
      "Epoch 56, batch 41/72, loss: 0.0500\n",
      "Epoch 56, batch 46/72, loss: 0.0195\n",
      "Epoch 56, batch 51/72, loss: 0.0492\n",
      "Epoch 56, batch 56/72, loss: 0.0336\n",
      "Epoch 56, batch 61/72, loss: 0.0259\n",
      "Epoch 56, batch 66/72, loss: 0.0291\n",
      "Epoch 56, batch 71/72, loss: 0.0221\n",
      "Epoch 56, train loss: 0.0299, train accuracy: 99.36%\n",
      "Epoch 56, val loss: 0.3655, val accuracy: 89.11%\n",
      "Epoch 57, batch 1/72, loss: 0.0241\n",
      "Epoch 57, batch 6/72, loss: 0.0645\n",
      "Epoch 57, batch 11/72, loss: 0.0264\n",
      "Epoch 57, batch 16/72, loss: 0.0217\n",
      "Epoch 57, batch 21/72, loss: 0.0128\n",
      "Epoch 57, batch 26/72, loss: 0.0293\n",
      "Epoch 57, batch 31/72, loss: 0.0145\n",
      "Epoch 57, batch 36/72, loss: 0.0257\n",
      "Epoch 57, batch 41/72, loss: 0.0406\n",
      "Epoch 57, batch 46/72, loss: 0.0342\n",
      "Epoch 57, batch 51/72, loss: 0.0308\n",
      "Epoch 57, batch 56/72, loss: 0.0423\n",
      "Epoch 57, batch 61/72, loss: 0.0354\n",
      "Epoch 57, batch 66/72, loss: 0.0236\n",
      "Epoch 57, batch 71/72, loss: 0.0552\n",
      "Epoch 57, train loss: 0.0311, train accuracy: 99.39%\n",
      "Epoch 57, val loss: 0.3714, val accuracy: 89.37%\n",
      "Epoch 58, batch 1/72, loss: 0.0259\n",
      "Epoch 58, batch 6/72, loss: 0.0329\n",
      "Epoch 58, batch 11/72, loss: 0.0147\n",
      "Epoch 58, batch 16/72, loss: 0.0184\n",
      "Epoch 58, batch 21/72, loss: 0.0272\n",
      "Epoch 58, batch 26/72, loss: 0.0156\n",
      "Epoch 58, batch 31/72, loss: 0.0371\n",
      "Epoch 58, batch 36/72, loss: 0.0411\n",
      "Epoch 58, batch 41/72, loss: 0.0231\n",
      "Epoch 58, batch 46/72, loss: 0.0233\n",
      "Epoch 58, batch 51/72, loss: 0.0261\n",
      "Epoch 58, batch 56/72, loss: 0.0495\n",
      "Epoch 58, batch 61/72, loss: 0.0171\n",
      "Epoch 58, batch 66/72, loss: 0.0141\n",
      "Epoch 58, batch 71/72, loss: 0.0256\n",
      "Epoch 58, train loss: 0.0238, train accuracy: 99.56%\n",
      "Epoch 58, val loss: 0.3940, val accuracy: 88.45%\n",
      "Epoch 59, batch 1/72, loss: 0.0956\n",
      "Epoch 59, batch 6/72, loss: 0.0279\n",
      "Epoch 59, batch 11/72, loss: 0.0237\n",
      "Epoch 59, batch 16/72, loss: 0.0260\n",
      "Epoch 59, batch 21/72, loss: 0.0349\n",
      "Epoch 59, batch 26/72, loss: 0.0462\n",
      "Epoch 59, batch 31/72, loss: 0.0125\n",
      "Epoch 59, batch 36/72, loss: 0.0448\n",
      "Epoch 59, batch 41/72, loss: 0.0749\n",
      "Epoch 59, batch 46/72, loss: 0.0650\n",
      "Epoch 59, batch 51/72, loss: 0.0667\n",
      "Epoch 59, batch 56/72, loss: 0.0605\n",
      "Epoch 59, batch 61/72, loss: 0.0165\n",
      "Epoch 59, batch 66/72, loss: 0.0331\n",
      "Epoch 59, batch 71/72, loss: 0.0342\n",
      "Epoch 59, train loss: 0.0359, train accuracy: 99.15%\n",
      "Epoch 59, val loss: 0.3834, val accuracy: 88.32%\n",
      "Epoch 60, batch 1/72, loss: 0.0470\n",
      "Epoch 60, batch 6/72, loss: 0.0204\n",
      "Epoch 60, batch 11/72, loss: 0.0262\n",
      "Epoch 60, batch 16/72, loss: 0.0197\n",
      "Epoch 60, batch 21/72, loss: 0.0325\n",
      "Epoch 60, batch 26/72, loss: 0.0380\n",
      "Epoch 60, batch 31/72, loss: 0.0394\n",
      "Epoch 60, batch 36/72, loss: 0.0537\n",
      "Epoch 60, batch 41/72, loss: 0.0318\n",
      "Epoch 60, batch 46/72, loss: 0.0240\n",
      "Epoch 60, batch 51/72, loss: 0.0287\n",
      "Epoch 60, batch 56/72, loss: 0.0255\n",
      "Epoch 60, batch 61/72, loss: 0.0183\n",
      "Epoch 60, batch 66/72, loss: 0.0093\n",
      "Epoch 60, batch 71/72, loss: 0.0458\n",
      "Epoch 60, train loss: 0.0269, train accuracy: 99.48%\n",
      "Epoch 60, val loss: 0.3647, val accuracy: 89.41%\n",
      "Epoch 61, batch 1/72, loss: 0.0260\n",
      "Epoch 61, batch 6/72, loss: 0.0129\n",
      "Epoch 61, batch 11/72, loss: 0.0224\n",
      "Epoch 61, batch 16/72, loss: 0.0156\n",
      "Epoch 61, batch 21/72, loss: 0.0203\n",
      "Epoch 61, batch 26/72, loss: 0.0182\n",
      "Epoch 61, batch 31/72, loss: 0.0287\n",
      "Epoch 61, batch 36/72, loss: 0.0200\n",
      "Epoch 61, batch 41/72, loss: 0.0266\n",
      "Epoch 61, batch 46/72, loss: 0.0572\n",
      "Epoch 61, batch 51/72, loss: 0.0274\n",
      "Epoch 61, batch 56/72, loss: 0.0151\n",
      "Epoch 61, batch 61/72, loss: 0.0192\n",
      "Epoch 61, batch 66/72, loss: 0.0262\n",
      "Epoch 61, batch 71/72, loss: 0.0108\n",
      "Epoch 61, train loss: 0.0235, train accuracy: 99.54%\n",
      "Epoch 61, val loss: 0.3701, val accuracy: 88.89%\n",
      "Epoch 62, batch 1/72, loss: 0.0180\n",
      "Epoch 62, batch 6/72, loss: 0.0229\n",
      "Epoch 62, batch 11/72, loss: 0.0047\n",
      "Epoch 62, batch 16/72, loss: 0.0084\n",
      "Epoch 62, batch 21/72, loss: 0.0131\n",
      "Epoch 62, batch 26/72, loss: 0.0278\n",
      "Epoch 62, batch 31/72, loss: 0.0532\n",
      "Epoch 62, batch 36/72, loss: 0.0124\n",
      "Epoch 62, batch 41/72, loss: 0.0355\n",
      "Epoch 62, batch 46/72, loss: 0.0382\n",
      "Epoch 62, batch 51/72, loss: 0.0323\n",
      "Epoch 62, batch 56/72, loss: 0.0151\n",
      "Epoch 62, batch 61/72, loss: 0.0171\n",
      "Epoch 62, batch 66/72, loss: 0.0228\n",
      "Epoch 62, batch 71/72, loss: 0.0308\n",
      "Epoch 62, train loss: 0.0261, train accuracy: 99.40%\n",
      "Epoch 62, val loss: 0.3924, val accuracy: 88.80%\n",
      "Epoch 63, batch 1/72, loss: 0.0193\n",
      "Epoch 63, batch 6/72, loss: 0.0225\n",
      "Epoch 63, batch 11/72, loss: 0.0543\n",
      "Epoch 63, batch 16/72, loss: 0.0130\n",
      "Epoch 63, batch 21/72, loss: 0.0124\n",
      "Epoch 63, batch 26/72, loss: 0.0677\n",
      "Epoch 63, batch 31/72, loss: 0.0306\n",
      "Epoch 63, batch 36/72, loss: 0.0328\n",
      "Epoch 63, batch 41/72, loss: 0.0760\n",
      "Epoch 63, batch 46/72, loss: 0.0560\n",
      "Epoch 63, batch 51/72, loss: 0.0355\n",
      "Epoch 63, batch 56/72, loss: 0.0449\n",
      "Epoch 63, batch 61/72, loss: 0.0218\n",
      "Epoch 63, batch 66/72, loss: 0.0432\n",
      "Epoch 63, batch 71/72, loss: 0.0475\n",
      "Epoch 63, train loss: 0.0361, train accuracy: 99.13%\n",
      "Epoch 63, val loss: 0.4074, val accuracy: 88.02%\n",
      "Epoch 64, batch 1/72, loss: 0.0400\n",
      "Epoch 64, batch 6/72, loss: 0.0250\n",
      "Epoch 64, batch 11/72, loss: 0.0592\n",
      "Epoch 64, batch 16/72, loss: 0.0202\n",
      "Epoch 64, batch 21/72, loss: 0.0149\n",
      "Epoch 64, batch 26/72, loss: 0.0211\n",
      "Epoch 64, batch 31/72, loss: 0.0455\n",
      "Epoch 64, batch 36/72, loss: 0.0158\n",
      "Epoch 64, batch 41/72, loss: 0.0252\n",
      "Epoch 64, batch 46/72, loss: 0.0248\n",
      "Epoch 64, batch 51/72, loss: 0.0354\n",
      "Epoch 64, batch 56/72, loss: 0.0304\n",
      "Epoch 64, batch 61/72, loss: 0.0265\n",
      "Epoch 64, batch 66/72, loss: 0.0196\n",
      "Epoch 64, batch 71/72, loss: 0.0379\n",
      "Epoch 64, train loss: 0.0319, train accuracy: 99.19%\n",
      "Epoch 64, val loss: 0.3629, val accuracy: 89.63%\n",
      "Epoch 65, batch 1/72, loss: 0.0196\n",
      "Epoch 65, batch 6/72, loss: 0.0263\n",
      "Epoch 65, batch 11/72, loss: 0.0156\n",
      "Epoch 65, batch 16/72, loss: 0.0160\n",
      "Epoch 65, batch 21/72, loss: 0.0214\n",
      "Epoch 65, batch 26/72, loss: 0.0230\n",
      "Epoch 65, batch 31/72, loss: 0.0144\n",
      "Epoch 65, batch 36/72, loss: 0.0084\n",
      "Epoch 65, batch 41/72, loss: 0.0121\n",
      "Epoch 65, batch 46/72, loss: 0.0221\n",
      "Epoch 65, batch 51/72, loss: 0.0390\n",
      "Epoch 65, batch 56/72, loss: 0.0405\n",
      "Epoch 65, batch 61/72, loss: 0.0092\n",
      "Epoch 65, batch 66/72, loss: 0.0404\n",
      "Epoch 65, batch 71/72, loss: 0.0487\n",
      "Epoch 65, train loss: 0.0231, train accuracy: 99.52%\n",
      "Epoch 65, val loss: 0.3592, val accuracy: 89.84%\n",
      "Epoch 66, batch 1/72, loss: 0.0213\n",
      "Epoch 66, batch 6/72, loss: 0.0183\n",
      "Epoch 66, batch 11/72, loss: 0.0205\n",
      "Epoch 66, batch 16/72, loss: 0.0102\n",
      "Epoch 66, batch 21/72, loss: 0.0877\n",
      "Epoch 66, batch 26/72, loss: 0.0191\n",
      "Epoch 66, batch 31/72, loss: 0.0236\n",
      "Epoch 66, batch 36/72, loss: 0.0160\n",
      "Epoch 66, batch 41/72, loss: 0.0234\n",
      "Epoch 66, batch 46/72, loss: 0.0135\n",
      "Epoch 66, batch 51/72, loss: 0.0334\n",
      "Epoch 66, batch 56/72, loss: 0.0112\n",
      "Epoch 66, batch 61/72, loss: 0.0068\n",
      "Epoch 66, batch 66/72, loss: 0.0164\n",
      "Epoch 66, batch 71/72, loss: 0.0161\n",
      "Epoch 66, train loss: 0.0227, train accuracy: 99.47%\n",
      "Epoch 66, val loss: 0.3610, val accuracy: 89.28%\n",
      "Epoch 67, batch 1/72, loss: 0.0148\n",
      "Epoch 67, batch 6/72, loss: 0.0212\n",
      "Epoch 67, batch 11/72, loss: 0.0075\n",
      "Epoch 67, batch 16/72, loss: 0.0096\n",
      "Epoch 67, batch 21/72, loss: 0.0069\n",
      "Epoch 67, batch 26/72, loss: 0.0311\n",
      "Epoch 67, batch 31/72, loss: 0.0076\n",
      "Epoch 67, batch 36/72, loss: 0.0130\n",
      "Epoch 67, batch 41/72, loss: 0.0091\n",
      "Epoch 67, batch 46/72, loss: 0.0191\n",
      "Epoch 67, batch 51/72, loss: 0.0109\n",
      "Epoch 67, batch 56/72, loss: 0.0174\n",
      "Epoch 67, batch 61/72, loss: 0.0127\n",
      "Epoch 67, batch 66/72, loss: 0.0199\n",
      "Epoch 67, batch 71/72, loss: 0.0136\n",
      "Epoch 67, train loss: 0.0156, train accuracy: 99.70%\n",
      "Epoch 67, val loss: 0.3910, val accuracy: 87.89%\n",
      "Epoch 68, batch 1/72, loss: 0.0129\n",
      "Epoch 68, batch 6/72, loss: 0.0126\n",
      "Epoch 68, batch 11/72, loss: 0.0321\n",
      "Epoch 68, batch 16/72, loss: 0.0296\n",
      "Epoch 68, batch 21/72, loss: 0.0267\n",
      "Epoch 68, batch 26/72, loss: 0.0315\n",
      "Epoch 68, batch 31/72, loss: 0.0342\n",
      "Epoch 68, batch 36/72, loss: 0.0085\n",
      "Epoch 68, batch 41/72, loss: 0.0076\n",
      "Epoch 68, batch 46/72, loss: 0.0145\n",
      "Epoch 68, batch 51/72, loss: 0.0371\n",
      "Epoch 68, batch 56/72, loss: 0.0124\n",
      "Epoch 68, batch 61/72, loss: 0.0242\n",
      "Epoch 68, batch 66/72, loss: 0.0378\n",
      "Epoch 68, batch 71/72, loss: 0.0369\n",
      "Epoch 68, train loss: 0.0216, train accuracy: 99.50%\n",
      "Epoch 68, val loss: 0.3603, val accuracy: 89.80%\n",
      "Epoch 69, batch 1/72, loss: 0.0105\n",
      "Epoch 69, batch 6/72, loss: 0.0156\n",
      "Epoch 69, batch 11/72, loss: 0.0268\n",
      "Epoch 69, batch 16/72, loss: 0.0119\n",
      "Epoch 69, batch 21/72, loss: 0.0173\n",
      "Epoch 69, batch 26/72, loss: 0.0078\n",
      "Epoch 69, batch 31/72, loss: 0.0187\n",
      "Epoch 69, batch 36/72, loss: 0.0084\n",
      "Epoch 69, batch 41/72, loss: 0.0127\n",
      "Epoch 69, batch 46/72, loss: 0.0107\n",
      "Epoch 69, batch 51/72, loss: 0.0158\n",
      "Epoch 69, batch 56/72, loss: 0.0069\n",
      "Epoch 69, batch 61/72, loss: 0.0192\n",
      "Epoch 69, batch 66/72, loss: 0.0310\n",
      "Epoch 69, batch 71/72, loss: 0.0074\n",
      "Epoch 69, train loss: 0.0157, train accuracy: 99.76%\n",
      "Epoch 69, val loss: 0.3739, val accuracy: 88.98%\n",
      "Epoch 70, batch 1/72, loss: 0.0054\n",
      "Epoch 70, batch 6/72, loss: 0.0096\n",
      "Epoch 70, batch 11/72, loss: 0.0092\n",
      "Epoch 70, batch 16/72, loss: 0.0149\n",
      "Epoch 70, batch 21/72, loss: 0.0182\n",
      "Epoch 70, batch 26/72, loss: 0.0139\n",
      "Epoch 70, batch 31/72, loss: 0.0133\n",
      "Epoch 70, batch 36/72, loss: 0.0087\n",
      "Epoch 70, batch 41/72, loss: 0.0106\n",
      "Epoch 70, batch 46/72, loss: 0.0158\n",
      "Epoch 70, batch 51/72, loss: 0.0123\n",
      "Epoch 70, batch 56/72, loss: 0.0104\n",
      "Epoch 70, batch 61/72, loss: 0.0178\n",
      "Epoch 70, batch 66/72, loss: 0.0097\n",
      "Epoch 70, batch 71/72, loss: 0.0073\n",
      "Epoch 70, train loss: 0.0160, train accuracy: 99.75%\n",
      "Epoch 70, val loss: 0.3743, val accuracy: 89.63%\n",
      "Epoch 71, batch 1/72, loss: 0.0407\n",
      "Epoch 71, batch 6/72, loss: 0.0202\n",
      "Epoch 71, batch 11/72, loss: 0.0117\n",
      "Epoch 71, batch 16/72, loss: 0.0173\n",
      "Epoch 71, batch 21/72, loss: 0.0042\n",
      "Epoch 71, batch 26/72, loss: 0.0098\n",
      "Epoch 71, batch 31/72, loss: 0.0147\n",
      "Epoch 71, batch 36/72, loss: 0.0161\n",
      "Epoch 71, batch 41/72, loss: 0.0150\n",
      "Epoch 71, batch 46/72, loss: 0.0092\n",
      "Epoch 71, batch 51/72, loss: 0.0160\n",
      "Epoch 71, batch 56/72, loss: 0.0104\n",
      "Epoch 71, batch 61/72, loss: 0.0072\n",
      "Epoch 71, batch 66/72, loss: 0.0125\n",
      "Epoch 71, batch 71/72, loss: 0.0111\n",
      "Epoch 71, train loss: 0.0188, train accuracy: 99.65%\n",
      "Epoch 71, val loss: 0.4067, val accuracy: 89.37%\n",
      "Epoch 72, batch 1/72, loss: 0.0125\n",
      "Epoch 72, batch 6/72, loss: 0.0112\n",
      "Epoch 72, batch 11/72, loss: 0.0211\n",
      "Epoch 72, batch 16/72, loss: 0.0068\n",
      "Epoch 72, batch 21/72, loss: 0.0079\n",
      "Epoch 72, batch 26/72, loss: 0.0213\n",
      "Epoch 72, batch 31/72, loss: 0.0125\n",
      "Epoch 72, batch 36/72, loss: 0.0442\n",
      "Epoch 72, batch 41/72, loss: 0.0141\n",
      "Epoch 72, batch 46/72, loss: 0.0128\n",
      "Epoch 72, batch 51/72, loss: 0.0227\n",
      "Epoch 72, batch 56/72, loss: 0.0085\n",
      "Epoch 72, batch 61/72, loss: 0.0203\n",
      "Epoch 72, batch 66/72, loss: 0.0100\n",
      "Epoch 72, batch 71/72, loss: 0.0146\n",
      "Epoch 72, train loss: 0.0161, train accuracy: 99.77%\n",
      "Epoch 72, val loss: 0.3678, val accuracy: 89.50%\n",
      "Epoch 73, batch 1/72, loss: 0.0199\n",
      "Epoch 73, batch 6/72, loss: 0.0098\n",
      "Epoch 73, batch 11/72, loss: 0.0137\n",
      "Epoch 73, batch 16/72, loss: 0.0091\n",
      "Epoch 73, batch 21/72, loss: 0.0046\n",
      "Epoch 73, batch 26/72, loss: 0.0094\n",
      "Epoch 73, batch 31/72, loss: 0.0179\n",
      "Epoch 73, batch 36/72, loss: 0.0257\n",
      "Epoch 73, batch 41/72, loss: 0.0254\n",
      "Epoch 73, batch 46/72, loss: 0.0068\n",
      "Epoch 73, batch 51/72, loss: 0.0116\n",
      "Epoch 73, batch 56/72, loss: 0.0215\n",
      "Epoch 73, batch 61/72, loss: 0.0346\n",
      "Epoch 73, batch 66/72, loss: 0.0088\n",
      "Epoch 73, batch 71/72, loss: 0.0083\n",
      "Epoch 73, train loss: 0.0170, train accuracy: 99.60%\n",
      "Epoch 73, val loss: 0.3711, val accuracy: 89.97%\n",
      "Epoch 74, batch 1/72, loss: 0.0068\n",
      "Epoch 74, batch 6/72, loss: 0.0285\n",
      "Epoch 74, batch 11/72, loss: 0.0039\n",
      "Epoch 74, batch 16/72, loss: 0.0201\n",
      "Epoch 74, batch 21/72, loss: 0.0058\n",
      "Epoch 74, batch 26/72, loss: 0.0127\n",
      "Epoch 74, batch 31/72, loss: 0.0222\n",
      "Epoch 74, batch 36/72, loss: 0.0101\n",
      "Epoch 74, batch 41/72, loss: 0.0079\n",
      "Epoch 74, batch 46/72, loss: 0.0154\n",
      "Epoch 74, batch 51/72, loss: 0.0066\n",
      "Epoch 74, batch 56/72, loss: 0.0101\n",
      "Epoch 74, batch 61/72, loss: 0.0072\n",
      "Epoch 74, batch 66/72, loss: 0.0090\n",
      "Epoch 74, batch 71/72, loss: 0.0189\n",
      "Epoch 74, train loss: 0.0129, train accuracy: 99.75%\n",
      "Epoch 74, val loss: 0.3758, val accuracy: 89.45%\n",
      "Epoch 75, batch 1/72, loss: 0.0046\n",
      "Epoch 75, batch 6/72, loss: 0.0070\n",
      "Epoch 75, batch 11/72, loss: 0.0067\n",
      "Epoch 75, batch 16/72, loss: 0.0104\n",
      "Epoch 75, batch 21/72, loss: 0.0182\n",
      "Epoch 75, batch 26/72, loss: 0.0085\n",
      "Epoch 75, batch 31/72, loss: 0.0149\n",
      "Epoch 75, batch 36/72, loss: 0.0107\n",
      "Epoch 75, batch 41/72, loss: 0.0091\n",
      "Epoch 75, batch 46/72, loss: 0.0116\n",
      "Epoch 75, batch 51/72, loss: 0.0030\n",
      "Epoch 75, batch 56/72, loss: 0.0055\n",
      "Epoch 75, batch 61/72, loss: 0.0239\n",
      "Epoch 75, batch 66/72, loss: 0.0069\n",
      "Epoch 75, batch 71/72, loss: 0.0195\n",
      "Epoch 75, train loss: 0.0099, train accuracy: 99.89%\n",
      "Epoch 75, val loss: 0.3692, val accuracy: 89.76%\n",
      "Epoch 76, batch 1/72, loss: 0.0071\n",
      "Epoch 76, batch 6/72, loss: 0.0097\n",
      "Epoch 76, batch 11/72, loss: 0.0075\n",
      "Epoch 76, batch 16/72, loss: 0.0033\n",
      "Epoch 76, batch 21/72, loss: 0.0048\n",
      "Epoch 76, batch 26/72, loss: 0.0060\n",
      "Epoch 76, batch 31/72, loss: 0.0076\n",
      "Epoch 76, batch 36/72, loss: 0.0069\n",
      "Epoch 76, batch 41/72, loss: 0.0382\n",
      "Epoch 76, batch 46/72, loss: 0.0047\n",
      "Epoch 76, batch 51/72, loss: 0.0304\n",
      "Epoch 76, batch 56/72, loss: 0.0066\n",
      "Epoch 76, batch 61/72, loss: 0.0096\n",
      "Epoch 76, batch 66/72, loss: 0.0201\n",
      "Epoch 76, batch 71/72, loss: 0.0056\n",
      "Epoch 76, train loss: 0.0114, train accuracy: 99.88%\n",
      "Epoch 76, val loss: 0.3890, val accuracy: 88.98%\n",
      "Epoch 77, batch 1/72, loss: 0.0042\n",
      "Epoch 77, batch 6/72, loss: 0.0118\n",
      "Epoch 77, batch 11/72, loss: 0.0204\n",
      "Epoch 77, batch 16/72, loss: 0.0069\n",
      "Epoch 77, batch 21/72, loss: 0.0236\n",
      "Epoch 77, batch 26/72, loss: 0.0321\n",
      "Epoch 77, batch 31/72, loss: 0.0227\n",
      "Epoch 77, batch 36/72, loss: 0.0364\n",
      "Epoch 77, batch 41/72, loss: 0.0081\n",
      "Epoch 77, batch 46/72, loss: 0.0038\n",
      "Epoch 77, batch 51/72, loss: 0.0108\n",
      "Epoch 77, batch 56/72, loss: 0.0180\n",
      "Epoch 77, batch 61/72, loss: 0.0044\n",
      "Epoch 77, batch 66/72, loss: 0.0042\n",
      "Epoch 77, batch 71/72, loss: 0.0059\n",
      "Epoch 77, train loss: 0.0135, train accuracy: 99.77%\n",
      "Epoch 77, val loss: 0.3915, val accuracy: 89.97%\n",
      "Epoch 78, batch 1/72, loss: 0.0039\n",
      "Epoch 78, batch 6/72, loss: 0.0081\n",
      "Epoch 78, batch 11/72, loss: 0.0157\n",
      "Epoch 78, batch 16/72, loss: 0.0075\n",
      "Epoch 78, batch 21/72, loss: 0.0085\n",
      "Epoch 78, batch 26/72, loss: 0.0038\n",
      "Epoch 78, batch 31/72, loss: 0.0127\n",
      "Epoch 78, batch 36/72, loss: 0.0506\n",
      "Epoch 78, batch 41/72, loss: 0.0061\n",
      "Epoch 78, batch 46/72, loss: 0.0064\n",
      "Epoch 78, batch 51/72, loss: 0.0122\n",
      "Epoch 78, batch 56/72, loss: 0.0208\n",
      "Epoch 78, batch 61/72, loss: 0.0206\n",
      "Epoch 78, batch 66/72, loss: 0.0067\n",
      "Epoch 78, batch 71/72, loss: 0.0118\n",
      "Epoch 78, train loss: 0.0097, train accuracy: 99.88%\n",
      "Epoch 78, val loss: 0.3724, val accuracy: 89.58%\n",
      "Epoch 79, batch 1/72, loss: 0.0032\n",
      "Epoch 79, batch 6/72, loss: 0.0050\n",
      "Epoch 79, batch 11/72, loss: 0.0069\n",
      "Epoch 79, batch 16/72, loss: 0.0102\n",
      "Epoch 79, batch 21/72, loss: 0.0043\n",
      "Epoch 79, batch 26/72, loss: 0.0039\n",
      "Epoch 79, batch 31/72, loss: 0.0067\n",
      "Epoch 79, batch 36/72, loss: 0.0092\n",
      "Epoch 79, batch 41/72, loss: 0.0081\n",
      "Epoch 79, batch 46/72, loss: 0.0200\n",
      "Epoch 79, batch 51/72, loss: 0.0107\n",
      "Epoch 79, batch 56/72, loss: 0.0205\n",
      "Epoch 79, batch 61/72, loss: 0.0065\n",
      "Epoch 79, batch 66/72, loss: 0.0102\n",
      "Epoch 79, batch 71/72, loss: 0.0108\n",
      "Epoch 79, train loss: 0.0092, train accuracy: 99.91%\n",
      "Epoch 79, val loss: 0.3792, val accuracy: 89.63%\n",
      "Epoch 80, batch 1/72, loss: 0.0086\n",
      "Epoch 80, batch 6/72, loss: 0.0073\n",
      "Epoch 80, batch 11/72, loss: 0.0071\n",
      "Epoch 80, batch 16/72, loss: 0.0099\n",
      "Epoch 80, batch 21/72, loss: 0.0162\n",
      "Epoch 80, batch 26/72, loss: 0.0035\n",
      "Epoch 80, batch 31/72, loss: 0.0124\n",
      "Epoch 80, batch 36/72, loss: 0.0109\n",
      "Epoch 80, batch 41/72, loss: 0.0082\n",
      "Epoch 80, batch 46/72, loss: 0.0088\n",
      "Epoch 80, batch 51/72, loss: 0.0072\n",
      "Epoch 80, batch 56/72, loss: 0.0135\n",
      "Epoch 80, batch 61/72, loss: 0.0276\n",
      "Epoch 80, batch 66/72, loss: 0.0301\n",
      "Epoch 80, batch 71/72, loss: 0.0117\n",
      "Epoch 80, train loss: 0.0126, train accuracy: 99.79%\n",
      "Epoch 80, val loss: 0.3852, val accuracy: 89.28%\n",
      "Epoch 81, batch 1/72, loss: 0.0179\n",
      "Epoch 81, batch 6/72, loss: 0.0057\n",
      "Epoch 81, batch 11/72, loss: 0.0208\n",
      "Epoch 81, batch 16/72, loss: 0.0095\n",
      "Epoch 81, batch 21/72, loss: 0.0050\n",
      "Epoch 81, batch 26/72, loss: 0.0038\n",
      "Epoch 81, batch 31/72, loss: 0.0177\n",
      "Epoch 81, batch 36/72, loss: 0.0106\n",
      "Epoch 81, batch 41/72, loss: 0.0091\n",
      "Epoch 81, batch 46/72, loss: 0.0074\n",
      "Epoch 81, batch 51/72, loss: 0.0043\n",
      "Epoch 81, batch 56/72, loss: 0.0080\n",
      "Epoch 81, batch 61/72, loss: 0.0058\n",
      "Epoch 81, batch 66/72, loss: 0.0098\n",
      "Epoch 81, batch 71/72, loss: 0.0081\n",
      "Epoch 81, train loss: 0.0103, train accuracy: 99.86%\n",
      "Epoch 81, val loss: 0.3832, val accuracy: 89.45%\n",
      "Epoch 82, batch 1/72, loss: 0.0084\n",
      "Epoch 82, batch 6/72, loss: 0.0058\n",
      "Epoch 82, batch 11/72, loss: 0.0105\n",
      "Epoch 82, batch 16/72, loss: 0.0100\n",
      "Epoch 82, batch 21/72, loss: 0.0056\n",
      "Epoch 82, batch 26/72, loss: 0.0027\n",
      "Epoch 82, batch 31/72, loss: 0.0049\n",
      "Epoch 82, batch 36/72, loss: 0.0163\n",
      "Epoch 82, batch 41/72, loss: 0.0038\n",
      "Epoch 82, batch 46/72, loss: 0.0086\n",
      "Epoch 82, batch 51/72, loss: 0.0103\n",
      "Epoch 82, batch 56/72, loss: 0.0054\n",
      "Epoch 82, batch 61/72, loss: 0.0076\n",
      "Epoch 82, batch 66/72, loss: 0.0078\n",
      "Epoch 82, batch 71/72, loss: 0.0070\n",
      "Epoch 82, train loss: 0.0070, train accuracy: 99.98%\n",
      "Epoch 82, val loss: 0.3737, val accuracy: 89.67%\n",
      "Epoch 83, batch 1/72, loss: 0.0079\n",
      "Epoch 83, batch 6/72, loss: 0.0054\n",
      "Epoch 83, batch 11/72, loss: 0.0130\n",
      "Epoch 83, batch 16/72, loss: 0.0097\n",
      "Epoch 83, batch 21/72, loss: 0.0129\n",
      "Epoch 83, batch 26/72, loss: 0.0069\n",
      "Epoch 83, batch 31/72, loss: 0.0056\n",
      "Epoch 83, batch 36/72, loss: 0.0052\n",
      "Epoch 83, batch 41/72, loss: 0.0048\n",
      "Epoch 83, batch 46/72, loss: 0.0120\n",
      "Epoch 83, batch 51/72, loss: 0.0043\n",
      "Epoch 83, batch 56/72, loss: 0.0162\n",
      "Epoch 83, batch 61/72, loss: 0.0057\n",
      "Epoch 83, batch 66/72, loss: 0.0036\n",
      "Epoch 83, batch 71/72, loss: 0.0046\n",
      "Epoch 83, train loss: 0.0081, train accuracy: 99.95%\n",
      "Epoch 83, val loss: 0.3704, val accuracy: 89.63%\n",
      "Epoch 84, batch 1/72, loss: 0.0063\n",
      "Epoch 84, batch 6/72, loss: 0.0068\n",
      "Epoch 84, batch 11/72, loss: 0.0044\n",
      "Epoch 84, batch 16/72, loss: 0.0055\n",
      "Epoch 84, batch 21/72, loss: 0.0107\n",
      "Epoch 84, batch 26/72, loss: 0.0270\n",
      "Epoch 84, batch 31/72, loss: 0.0132\n",
      "Epoch 84, batch 36/72, loss: 0.0078\n",
      "Epoch 84, batch 41/72, loss: 0.0111\n",
      "Epoch 84, batch 46/72, loss: 0.0044\n",
      "Epoch 84, batch 51/72, loss: 0.0054\n",
      "Epoch 84, batch 56/72, loss: 0.0191\n",
      "Epoch 84, batch 61/72, loss: 0.0075\n",
      "Epoch 84, batch 66/72, loss: 0.0090\n",
      "Epoch 84, batch 71/72, loss: 0.0042\n",
      "Epoch 84, train loss: 0.0096, train accuracy: 99.86%\n",
      "Epoch 84, val loss: 0.3913, val accuracy: 88.93%\n",
      "Epoch 85, batch 1/72, loss: 0.0078\n",
      "Epoch 85, batch 6/72, loss: 0.0084\n",
      "Epoch 85, batch 11/72, loss: 0.0067\n",
      "Epoch 85, batch 16/72, loss: 0.0044\n",
      "Epoch 85, batch 21/72, loss: 0.0111\n",
      "Epoch 85, batch 26/72, loss: 0.0073\n",
      "Epoch 85, batch 31/72, loss: 0.0061\n",
      "Epoch 85, batch 36/72, loss: 0.0124\n",
      "Epoch 85, batch 41/72, loss: 0.0126\n",
      "Epoch 85, batch 46/72, loss: 0.0086\n",
      "Epoch 85, batch 51/72, loss: 0.0056\n",
      "Epoch 85, batch 56/72, loss: 0.0239\n",
      "Epoch 85, batch 61/72, loss: 0.0044\n",
      "Epoch 85, batch 66/72, loss: 0.0129\n",
      "Epoch 85, batch 71/72, loss: 0.0096\n",
      "Epoch 85, train loss: 0.0113, train accuracy: 99.76%\n",
      "Epoch 85, val loss: 0.3763, val accuracy: 89.80%\n",
      "Epoch 86, batch 1/72, loss: 0.0043\n",
      "Epoch 86, batch 6/72, loss: 0.0084\n",
      "Epoch 86, batch 11/72, loss: 0.0066\n",
      "Epoch 86, batch 16/72, loss: 0.0094\n",
      "Epoch 86, batch 21/72, loss: 0.0032\n",
      "Epoch 86, batch 26/72, loss: 0.0089\n",
      "Epoch 86, batch 31/72, loss: 0.0084\n",
      "Epoch 86, batch 36/72, loss: 0.0131\n",
      "Epoch 86, batch 41/72, loss: 0.0052\n",
      "Epoch 86, batch 46/72, loss: 0.0063\n",
      "Epoch 86, batch 51/72, loss: 0.0086\n",
      "Epoch 86, batch 56/72, loss: 0.0043\n",
      "Epoch 86, batch 61/72, loss: 0.0034\n",
      "Epoch 86, batch 66/72, loss: 0.0073\n",
      "Epoch 86, batch 71/72, loss: 0.0067\n",
      "Epoch 86, train loss: 0.0082, train accuracy: 99.89%\n",
      "Epoch 86, val loss: 0.3729, val accuracy: 89.71%\n",
      "Epoch 87, batch 1/72, loss: 0.0162\n",
      "Epoch 87, batch 6/72, loss: 0.0281\n",
      "Epoch 87, batch 11/72, loss: 0.0193\n",
      "Epoch 87, batch 16/72, loss: 0.0097\n",
      "Epoch 87, batch 21/72, loss: 0.0054\n",
      "Epoch 87, batch 26/72, loss: 0.0169\n",
      "Epoch 87, batch 31/72, loss: 0.0043\n",
      "Epoch 87, batch 36/72, loss: 0.0100\n",
      "Epoch 87, batch 41/72, loss: 0.0126\n",
      "Epoch 87, batch 46/72, loss: 0.0068\n",
      "Epoch 87, batch 51/72, loss: 0.0061\n",
      "Epoch 87, batch 56/72, loss: 0.0082\n",
      "Epoch 87, batch 61/72, loss: 0.0066\n",
      "Epoch 87, batch 66/72, loss: 0.0107\n",
      "Epoch 87, batch 71/72, loss: 0.0104\n",
      "Epoch 87, train loss: 0.0124, train accuracy: 99.77%\n",
      "Epoch 87, val loss: 0.3822, val accuracy: 89.45%\n",
      "Epoch 88, batch 1/72, loss: 0.0095\n",
      "Epoch 88, batch 6/72, loss: 0.0063\n",
      "Epoch 88, batch 11/72, loss: 0.0045\n",
      "Epoch 88, batch 16/72, loss: 0.0181\n",
      "Epoch 88, batch 21/72, loss: 0.0164\n",
      "Epoch 88, batch 26/72, loss: 0.0051\n",
      "Epoch 88, batch 31/72, loss: 0.0112\n",
      "Epoch 88, batch 36/72, loss: 0.0177\n",
      "Epoch 88, batch 41/72, loss: 0.0040\n",
      "Epoch 88, batch 46/72, loss: 0.0084\n",
      "Epoch 88, batch 51/72, loss: 0.0102\n",
      "Epoch 88, batch 56/72, loss: 0.0136\n",
      "Epoch 88, batch 61/72, loss: 0.0077\n",
      "Epoch 88, batch 66/72, loss: 0.0093\n",
      "Epoch 88, batch 71/72, loss: 0.0387\n",
      "Epoch 88, train loss: 0.0116, train accuracy: 99.84%\n",
      "Epoch 88, val loss: 0.3805, val accuracy: 89.97%\n",
      "Epoch 89, batch 1/72, loss: 0.0079\n",
      "Epoch 89, batch 6/72, loss: 0.0093\n",
      "Epoch 89, batch 11/72, loss: 0.0140\n",
      "Epoch 89, batch 16/72, loss: 0.0147\n",
      "Epoch 89, batch 21/72, loss: 0.0132\n",
      "Epoch 89, batch 26/72, loss: 0.0081\n",
      "Epoch 89, batch 31/72, loss: 0.0147\n",
      "Epoch 89, batch 36/72, loss: 0.0265\n",
      "Epoch 89, batch 41/72, loss: 0.0053\n",
      "Epoch 89, batch 46/72, loss: 0.0043\n",
      "Epoch 89, batch 51/72, loss: 0.0082\n",
      "Epoch 89, batch 56/72, loss: 0.0053\n",
      "Epoch 89, batch 61/72, loss: 0.0149\n",
      "Epoch 89, batch 66/72, loss: 0.0055\n",
      "Epoch 89, batch 71/72, loss: 0.0048\n",
      "Epoch 89, train loss: 0.0116, train accuracy: 99.83%\n",
      "Epoch 89, val loss: 0.3752, val accuracy: 89.93%\n",
      "Epoch 90, batch 1/72, loss: 0.0261\n",
      "Epoch 90, batch 6/72, loss: 0.0105\n",
      "Epoch 90, batch 11/72, loss: 0.0147\n",
      "Epoch 90, batch 16/72, loss: 0.0192\n",
      "Epoch 90, batch 21/72, loss: 0.0341\n",
      "Epoch 90, batch 26/72, loss: 0.0101\n",
      "Epoch 90, batch 31/72, loss: 0.0069\n",
      "Epoch 90, batch 36/72, loss: 0.0243\n",
      "Epoch 90, batch 41/72, loss: 0.0048\n",
      "Epoch 90, batch 46/72, loss: 0.0072\n",
      "Epoch 90, batch 51/72, loss: 0.0147\n",
      "Epoch 90, batch 56/72, loss: 0.0075\n",
      "Epoch 90, batch 61/72, loss: 0.0047\n",
      "Epoch 90, batch 66/72, loss: 0.0131\n",
      "Epoch 90, batch 71/72, loss: 0.0143\n",
      "Epoch 90, train loss: 0.0116, train accuracy: 99.85%\n",
      "Epoch 90, val loss: 0.3834, val accuracy: 89.11%\n",
      "Epoch 91, batch 1/72, loss: 0.0198\n",
      "Epoch 91, batch 6/72, loss: 0.0135\n",
      "Epoch 91, batch 11/72, loss: 0.0066\n",
      "Epoch 91, batch 16/72, loss: 0.0042\n",
      "Epoch 91, batch 21/72, loss: 0.0088\n",
      "Epoch 91, batch 26/72, loss: 0.0081\n",
      "Epoch 91, batch 31/72, loss: 0.0031\n",
      "Epoch 91, batch 36/72, loss: 0.0181\n",
      "Epoch 91, batch 41/72, loss: 0.0070\n",
      "Epoch 91, batch 46/72, loss: 0.0081\n",
      "Epoch 91, batch 51/72, loss: 0.0095\n",
      "Epoch 91, batch 56/72, loss: 0.0012\n",
      "Epoch 91, batch 61/72, loss: 0.0064\n",
      "Epoch 91, batch 66/72, loss: 0.0171\n",
      "Epoch 91, batch 71/72, loss: 0.0109\n",
      "Epoch 91, train loss: 0.0096, train accuracy: 99.82%\n",
      "Epoch 91, val loss: 0.3867, val accuracy: 89.63%\n",
      "Epoch 92, batch 1/72, loss: 0.0050\n",
      "Epoch 92, batch 6/72, loss: 0.0152\n",
      "Epoch 92, batch 11/72, loss: 0.0763\n",
      "Epoch 92, batch 16/72, loss: 0.0358\n",
      "Epoch 92, batch 21/72, loss: 0.0113\n",
      "Epoch 92, batch 26/72, loss: 0.0100\n",
      "Epoch 92, batch 31/72, loss: 0.0086\n",
      "Epoch 92, batch 36/72, loss: 0.0076\n",
      "Epoch 92, batch 41/72, loss: 0.0274\n",
      "Epoch 92, batch 46/72, loss: 0.0114\n",
      "Epoch 92, batch 51/72, loss: 0.0215\n",
      "Epoch 92, batch 56/72, loss: 0.0097\n",
      "Epoch 92, batch 61/72, loss: 0.0309\n",
      "Epoch 92, batch 66/72, loss: 0.0161\n",
      "Epoch 92, batch 71/72, loss: 0.0404\n",
      "Epoch 92, train loss: 0.0148, train accuracy: 99.71%\n",
      "Epoch 92, val loss: 0.4051, val accuracy: 88.98%\n",
      "Epoch 93, batch 1/72, loss: 0.0190\n",
      "Epoch 93, batch 6/72, loss: 0.0147\n",
      "Epoch 93, batch 11/72, loss: 0.0070\n",
      "Epoch 93, batch 16/72, loss: 0.0055\n",
      "Epoch 93, batch 21/72, loss: 0.0200\n",
      "Epoch 93, batch 26/72, loss: 0.0069\n",
      "Epoch 93, batch 31/72, loss: 0.0259\n",
      "Epoch 93, batch 36/72, loss: 0.0160\n",
      "Epoch 93, batch 41/72, loss: 0.0124\n",
      "Epoch 93, batch 46/72, loss: 0.0106\n",
      "Epoch 93, batch 51/72, loss: 0.0066\n",
      "Epoch 93, batch 56/72, loss: 0.0075\n",
      "Epoch 93, batch 61/72, loss: 0.0051\n",
      "Epoch 93, batch 66/72, loss: 0.0058\n",
      "Epoch 93, batch 71/72, loss: 0.0050\n",
      "Epoch 93, train loss: 0.0098, train accuracy: 99.84%\n",
      "Epoch 93, val loss: 0.3752, val accuracy: 89.76%\n",
      "Epoch 94, batch 1/72, loss: 0.0027\n",
      "Epoch 94, batch 6/72, loss: 0.0120\n",
      "Epoch 94, batch 11/72, loss: 0.0184\n",
      "Epoch 94, batch 16/72, loss: 0.0138\n",
      "Epoch 94, batch 21/72, loss: 0.0091\n",
      "Epoch 94, batch 26/72, loss: 0.0049\n",
      "Epoch 94, batch 31/72, loss: 0.0072\n",
      "Epoch 94, batch 36/72, loss: 0.0076\n",
      "Epoch 94, batch 41/72, loss: 0.0095\n",
      "Epoch 94, batch 46/72, loss: 0.0147\n",
      "Epoch 94, batch 51/72, loss: 0.0041\n",
      "Epoch 94, batch 56/72, loss: 0.0054\n",
      "Epoch 94, batch 61/72, loss: 0.0090\n",
      "Epoch 94, batch 66/72, loss: 0.0026\n",
      "Epoch 94, batch 71/72, loss: 0.0110\n",
      "Epoch 94, train loss: 0.0081, train accuracy: 99.90%\n",
      "Epoch 94, val loss: 0.3649, val accuracy: 90.06%\n",
      "Epoch 95, batch 1/72, loss: 0.0058\n",
      "Epoch 95, batch 6/72, loss: 0.0041\n",
      "Epoch 95, batch 11/72, loss: 0.0082\n",
      "Epoch 95, batch 16/72, loss: 0.0070\n",
      "Epoch 95, batch 21/72, loss: 0.0062\n",
      "Epoch 95, batch 26/72, loss: 0.0106\n",
      "Epoch 95, batch 31/72, loss: 0.0046\n",
      "Epoch 95, batch 36/72, loss: 0.0036\n",
      "Epoch 95, batch 41/72, loss: 0.0192\n",
      "Epoch 95, batch 46/72, loss: 0.0048\n",
      "Epoch 95, batch 51/72, loss: 0.0111\n",
      "Epoch 95, batch 56/72, loss: 0.0045\n",
      "Epoch 95, batch 61/72, loss: 0.0070\n",
      "Epoch 95, batch 66/72, loss: 0.0047\n",
      "Epoch 95, batch 71/72, loss: 0.0030\n",
      "Epoch 95, train loss: 0.0062, train accuracy: 99.97%\n",
      "Epoch 95, val loss: 0.3709, val accuracy: 89.58%\n",
      "Epoch 96, batch 1/72, loss: 0.0017\n",
      "Epoch 96, batch 6/72, loss: 0.0044\n",
      "Epoch 96, batch 11/72, loss: 0.0044\n",
      "Epoch 96, batch 16/72, loss: 0.0040\n",
      "Epoch 96, batch 21/72, loss: 0.0024\n",
      "Epoch 96, batch 26/72, loss: 0.0039\n",
      "Epoch 96, batch 31/72, loss: 0.0109\n",
      "Epoch 96, batch 36/72, loss: 0.0055\n",
      "Epoch 96, batch 41/72, loss: 0.0073\n",
      "Epoch 96, batch 46/72, loss: 0.0128\n",
      "Epoch 96, batch 51/72, loss: 0.0062\n",
      "Epoch 96, batch 56/72, loss: 0.0045\n",
      "Epoch 96, batch 61/72, loss: 0.0068\n",
      "Epoch 96, batch 66/72, loss: 0.0061\n",
      "Epoch 96, batch 71/72, loss: 0.0062\n",
      "Epoch 96, train loss: 0.0067, train accuracy: 99.90%\n",
      "Epoch 96, val loss: 0.4122, val accuracy: 89.32%\n",
      "Epoch 97, batch 1/72, loss: 0.0037\n",
      "Epoch 97, batch 6/72, loss: 0.0031\n",
      "Epoch 97, batch 11/72, loss: 0.0048\n",
      "Epoch 97, batch 16/72, loss: 0.0026\n",
      "Epoch 97, batch 21/72, loss: 0.0034\n",
      "Epoch 97, batch 26/72, loss: 0.0091\n",
      "Epoch 97, batch 31/72, loss: 0.0033\n",
      "Epoch 97, batch 36/72, loss: 0.0025\n",
      "Epoch 97, batch 41/72, loss: 0.0243\n",
      "Epoch 97, batch 46/72, loss: 0.0046\n",
      "Epoch 97, batch 51/72, loss: 0.0102\n",
      "Epoch 97, batch 56/72, loss: 0.0052\n",
      "Epoch 97, batch 61/72, loss: 0.0023\n",
      "Epoch 97, batch 66/72, loss: 0.0057\n",
      "Epoch 97, batch 71/72, loss: 0.0046\n",
      "Epoch 97, train loss: 0.0058, train accuracy: 99.92%\n",
      "Epoch 97, val loss: 0.3778, val accuracy: 90.02%\n",
      "Epoch 98, batch 1/72, loss: 0.0043\n",
      "Epoch 98, batch 6/72, loss: 0.0025\n",
      "Epoch 98, batch 11/72, loss: 0.0026\n",
      "Epoch 98, batch 16/72, loss: 0.0016\n",
      "Epoch 98, batch 21/72, loss: 0.0027\n",
      "Epoch 98, batch 26/72, loss: 0.0037\n",
      "Epoch 98, batch 31/72, loss: 0.0197\n",
      "Epoch 98, batch 36/72, loss: 0.0040\n",
      "Epoch 98, batch 41/72, loss: 0.0119\n",
      "Epoch 98, batch 46/72, loss: 0.0041\n",
      "Epoch 98, batch 51/72, loss: 0.0043\n",
      "Epoch 98, batch 56/72, loss: 0.0109\n",
      "Epoch 98, batch 61/72, loss: 0.0158\n",
      "Epoch 98, batch 66/72, loss: 0.0078\n",
      "Epoch 98, batch 71/72, loss: 0.0085\n",
      "Epoch 98, train loss: 0.0063, train accuracy: 99.91%\n",
      "Epoch 98, val loss: 0.3864, val accuracy: 89.80%\n",
      "Epoch 99, batch 1/72, loss: 0.0043\n",
      "Epoch 99, batch 6/72, loss: 0.0078\n",
      "Epoch 99, batch 11/72, loss: 0.0026\n",
      "Epoch 99, batch 16/72, loss: 0.0055\n",
      "Epoch 99, batch 21/72, loss: 0.0034\n",
      "Epoch 99, batch 26/72, loss: 0.0076\n",
      "Epoch 99, batch 31/72, loss: 0.0056\n",
      "Epoch 99, batch 36/72, loss: 0.0027\n",
      "Epoch 99, batch 41/72, loss: 0.0076\n",
      "Epoch 99, batch 46/72, loss: 0.0039\n",
      "Epoch 99, batch 51/72, loss: 0.0038\n",
      "Epoch 99, batch 56/72, loss: 0.0062\n",
      "Epoch 99, batch 61/72, loss: 0.0069\n",
      "Epoch 99, batch 66/72, loss: 0.0026\n",
      "Epoch 99, batch 71/72, loss: 0.0041\n",
      "Epoch 99, train loss: 0.0070, train accuracy: 99.95%\n",
      "Epoch 99, val loss: 0.3930, val accuracy: 89.37%\n",
      "Epoch 100, batch 1/72, loss: 0.0121\n",
      "Epoch 100, batch 6/72, loss: 0.0081\n",
      "Epoch 100, batch 11/72, loss: 0.0037\n",
      "Epoch 100, batch 16/72, loss: 0.0323\n",
      "Epoch 100, batch 21/72, loss: 0.0035\n",
      "Epoch 100, batch 26/72, loss: 0.0090\n",
      "Epoch 100, batch 31/72, loss: 0.0045\n",
      "Epoch 100, batch 36/72, loss: 0.0105\n",
      "Epoch 100, batch 41/72, loss: 0.0028\n",
      "Epoch 100, batch 46/72, loss: 0.0109\n",
      "Epoch 100, batch 51/72, loss: 0.0105\n",
      "Epoch 100, batch 56/72, loss: 0.0051\n",
      "Epoch 100, batch 61/72, loss: 0.0027\n",
      "Epoch 100, batch 66/72, loss: 0.0049\n",
      "Epoch 100, batch 71/72, loss: 0.0075\n",
      "Epoch 100, train loss: 0.0112, train accuracy: 99.77%\n",
      "Epoch 100, val loss: 0.3708, val accuracy: 89.97%\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, val_losses, val_accs = train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b66e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models_v5/best_model_v5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a4296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_accuracy(train_losses, val_losses, train_accs, val_accs):\n",
    "    # Create figure and axes\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot loss curves\n",
    "    ax1.plot(train_losses, label=\"Training Loss\", color=\"blue\")\n",
    "    ax1.plot(val_losses, label=\"Validation Loss\", color=\"orange\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot accuracy curves\n",
    "    ax2.plot(train_accs, label=\"Training Accuracy\", color=\"green\")\n",
    "    ax2.plot(val_accs, label=\"Validation Accuracy\", color=\"red\")\n",
    "    \n",
    "    \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"./models_v5/loss_accuracy_v5.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b983a7d0-4506-4a87-90b5-3713e6c088b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_accuracy(train_losses, val_losses, train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55958b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
