{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1c7ebc-df5f-4c4e-b8be-1f69a79f8a2c",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Before you have to do something we will show you some basics on dataloading and preprocessing on the dataset used in this challenge as well as a basic network setup.  \n",
    "You can than later re-use parts of this to make your life a little bit easier, but you don't have to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617147a-5efd-4572-9ac0-6b48d1269fa3",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "To work with any kind of data we first have to load it. For this we use a dataloader that reads the images as well as their labels and transforms them into pytorch readable tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090711b-668a-4bab-a4d7-686081d239cb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class RSiMCCDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        # get images\n",
    "        image_files = [x.resolve() for x in pathlib.Path(\".\").glob('data/*/*')]\n",
    "        # Image.open() has a bug, this is a workaround\n",
    "        self.images=[read_image(str(p)) for p in image_files] \n",
    "        # get labels from image path\n",
    "        labels = [x.parts[-2] for x in image_files]\n",
    "        self.classes = sorted(list(set(labels)))\n",
    "        self.labels = [self.label_to_tensor(lbl) for lbl in labels]\n",
    "\n",
    "        assert len(self.labels) == len(self.images), f\"Found {len(self.labels)} labels and {len(self.images)} images\"\n",
    "\n",
    "    def label_to_tensor(self, lbl):\n",
    "        \"\"\"\n",
    "        Converts the string label to a one-hot tensor where every entry is zero except the label which is one.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert lbl in self.classes, f\"Class {lbl} not a valid class (valid classes: {self.classes})\"\n",
    "        t = torch.zeros(len(self.classes))\n",
    "        t[self.classes.index(lbl)] = 1\n",
    "        return t\n",
    "\n",
    "    def tensor_to_label(self, t):\n",
    "        \"\"\"\n",
    "        Returns the classname in string format\n",
    "        \"\"\"\n",
    "        assert len(t.shape) == 1, f\"Can only convert 1-dimensional tensors (shape of tensor: {t.shape})\"\n",
    "        assert len(t) == len(self.classes), f\"Lenght of tensor ({len(t)}) does not match number of classes ({len(classes)})\"\n",
    "        return self.classes[t.argmax()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].float()/255\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685aa618-6d38-4ff5-bac6-2e16f8c7a25e",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Now lets load the dataset and look at some examples by just randomly loading the images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f108f-b1c0-4ab8-a331-3a6d038d2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RSiMCCDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d3a99-809d-456d-b3ed-7db865d1aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, len(ds))\n",
    "img, lbl = ds[r]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.title(ds.tensor_to_label(lbl) + \"\\nIndex: \" + str(r))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476cf3f-c274-47fc-a876-b742f7148e26",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "Next up we need to create a model that should be trained using our data.  \n",
    "For this we will be using a pre-defined model from pytorch.\n",
    "\n",
    "*Note: We are not training or evaluating here, this is later your task to decide how to.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbe75c-d561-4433-b71d-46fcdb353a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18 as def_net\n",
    "from torchvision.models import ResNet18_Weights as def_weight \n",
    "\n",
    "model = def_net(num_classes=len(ds.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffde19e-8c31-4162-8e4d-f6211ee576ad",
   "metadata": {},
   "source": [
    "Let's check if this works - this is not about accuracy but just to see if the model runs with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fc5d9-2e19-4561-80f8-7ff8eed1c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# run model\n",
    "model.eval()\n",
    "dl = DataLoader(dataset=ds, num_workers=4, batch_size=1, shuffle=True)\n",
    "batch = next(iter(dl))\n",
    "res = model(batch[0])\n",
    "\n",
    "# show results\n",
    "plt.imshow(batch[0].squeeze().permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.title(\"Input\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Result: {ds.tensor_to_label(res.squeeze())}\")\n",
    "print(f\"Actual: {ds.tensor_to_label(batch[1].squeeze())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38166d53-39c9-466d-8355-c50147c3ebf3",
   "metadata": {},
   "source": [
    "# Coding Challenge\n",
    "Now that you saw how the data and model could be loaded it is your task to create a model that performs better. For this please fill out the functions in [`CodingChallenge.py`](CodingChallenge.py).  \n",
    "You may re-use code from this notebook if you wish to and you don't have to re-invent the wheel.\n",
    "\n",
    "To fully complete the challenge you have to\n",
    "1. Analyze the data\n",
    "   * How you do this is up to you and optional codes created in this step don't have to be submitted.\n",
    "2. Load the data\n",
    "   * This may include additional steps then just loading\n",
    "3. Load a model\n",
    "   * Beware of changes to the model that may apply\n",
    "   * Your model can be based on an existing architecture (like above) or custom\n",
    "4. Train the model\n",
    "   * This may include several steps\n",
    "5. Evaluate the model\n",
    "   * The result should be a single score applicable to this task\n",
    "6. Summarize your findings\n",
    "   * This may include results of the training process or anything else you want to share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108804ca-81ee-4913-ae7f-046cce08d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CodingChallenge as CodingChallenge\n",
    "# creating model and dataset\n",
    "my_model = CodingChallenge.get_my_model()\n",
    "my_ds    = CodingChallenge.get_my_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aeae29c-bf22-4202-bb0b-9bf7b2f00e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([200, 3, 64, 64])\n",
      "Labels batch shape:  torch.Size([200, 10])\n",
      "\n",
      "Training the model with 3 epochs for 47 batches  of size 200 each, representing an amount of 80% of the dataset i.e. 9215 elements.\n",
      "Training algorithm is SGD with momentum 0.9 and learning rate 1e-3 optimizing the crossentropy loss.\n",
      "Using device cuda.\n",
      "\n",
      "The loss used is CrossEntropyLoss() and the model is a DeepResCNN with 10 classes predicted.\n",
      "The number of parameters is 213930.\n",
      "\n",
      "Epoch 1, batch 1/47, loss: 2.5678\n",
      "Epoch 1, batch 6/47, loss: 2.1134\n",
      "Epoch 1, batch 11/47, loss: 1.9631\n",
      "Epoch 1, batch 16/47, loss: 1.6819\n",
      "Epoch 1, batch 21/47, loss: 1.5774\n",
      "Epoch 1, batch 26/47, loss: 1.5516\n",
      "Epoch 1, batch 31/47, loss: 1.4499\n",
      "Epoch 1, batch 36/47, loss: 1.4087\n",
      "Epoch 1, batch 41/47, loss: 1.3141\n",
      "Epoch 1, batch 46/47, loss: 1.3124\n",
      "Epoch 1, train loss: 1.6788, train accuracy: 40.87%\n",
      "Epoch 1, val loss: 1.2693, val accuracy: 58.59%\n",
      "Epoch 2, batch 1/47, loss: 1.2654\n",
      "Epoch 2, batch 6/47, loss: 1.2767\n",
      "Epoch 2, batch 11/47, loss: 1.1500\n",
      "Epoch 2, batch 16/47, loss: 1.0416\n",
      "Epoch 2, batch 21/47, loss: 0.9880\n",
      "Epoch 2, batch 26/47, loss: 1.0060\n",
      "Epoch 2, batch 31/47, loss: 1.0101\n",
      "Epoch 2, batch 36/47, loss: 0.9746\n",
      "Epoch 2, batch 41/47, loss: 0.9928\n",
      "Epoch 2, batch 46/47, loss: 0.8100\n",
      "Epoch 2, train loss: 1.0951, train accuracy: 65.20%\n",
      "Epoch 2, val loss: 1.0220, val accuracy: 66.88%\n",
      "Epoch 3, batch 1/47, loss: 0.9517\n",
      "Epoch 3, batch 6/47, loss: 0.9150\n",
      "Epoch 3, batch 11/47, loss: 0.9013\n",
      "Epoch 3, batch 16/47, loss: 0.8226\n",
      "Epoch 3, batch 21/47, loss: 0.9258\n",
      "Epoch 3, batch 26/47, loss: 0.9151\n",
      "Epoch 3, batch 31/47, loss: 0.8070\n",
      "Epoch 3, batch 36/47, loss: 0.8865\n",
      "Epoch 3, batch 41/47, loss: 0.8350\n",
      "Epoch 3, batch 46/47, loss: 0.7800\n",
      "Epoch 3, train loss: 0.8894, train accuracy: 70.93%\n",
      "Epoch 3, val loss: 0.9051, val accuracy: 70.66%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "my_model = CodingChallenge.train(my_model, my_ds)\n",
    "# we keep the val_dataset for the final_evaluate function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3450622-1207-4e49-a118-cf3e678a8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# for the needs of this function (which is costly as we need to iterate over the full validation dataset pointwise), it is a bit long (15sec)\n",
    "the_final_score = CodingChallenge.final_evaluate(my_model, my_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72e2aff-d2ae-4f36-b062-4aa340e4b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant information has been displayed during training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarize the findings\n",
    "CodingChallenge.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447c5db-5363-4972-9038-42cf3408f0c2",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "For the documentation of you work, please write a short (max. 2 pages) report including but not limited to:\n",
    "\n",
    "1. Discuss the data analysis and your observations (using plots, tables, statistical reports, etc.)\n",
    "2. Provide a description of the model you selected, evaluation metric(s) and the result.\n",
    "3. Provide details of the selected deep model learning procedure (hyperparameters, augmentations if any, loss curves, etc.).\n",
    "4. Discuss the methods that can be used for improving the result of your training. Methods of this discussion don't have to be implemented by you.\n",
    "5. Discuss your observations and potential problems and possible improvements to your current solution.\n",
    "\n",
    "For all points you may add references (e.g. for methods) from the scientific literature when appropriate. References don't count to your 2 page limit.\n",
    "\n",
    "# Submission\n",
    "\n",
    "For the submission, please submit a **single zip file** called `<LastName>_<FirstName>_cv4rs_cc.zip` containing **exacly** two files:\n",
    "\n",
    "1. Your report as `report_<LastName>_<FirstName>.pdf`\n",
    "2. Your code as `CodingChallenge.py`\n",
    "\n",
    "Please do **not submit** the `CodingChallenge.ipynb` - any changes on this file will not be graded.\n",
    "\n",
    "Note, that only your code is to be submitted and no model checkpoints or similar. Therefore you should take scientific practices like reproducablity into account.\n",
    "\n",
    "## Examples:\n",
    "1. Name: Max Mustermann  \n",
    "   Submission:\n",
    "   ```\n",
    "       .  \n",
    "       └── Mustermann_Max_cv4rs_cc.zip  \n",
    "           ├── report_Mustermann_Max.pdf  \n",
    "           └── CodingChallenge.py\n",
    "   ```  \n",
    "\n",
    "\n",
    "3. Name: Marie Anna Musterfrau  \n",
    "   Submission:\n",
    "   ```\n",
    "       .  \n",
    "       └── Musterfrau_Marie_cv4rs_cc.zip  \n",
    "           ├── report_Musterfrau_Marie.pdf  \n",
    "           └── CodingChallenge.py  \n",
    "   ```\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983a7d0-4506-4a87-90b5-3713e6c088b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
